[2021-04-14 19:00:01,837] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,840] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,841] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,842] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,843] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,843] INFO Server environment:java.class.path=D:\kafka\kafka_2.13-2.5.0\libs\activation-1.1.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\aopalliance-repackaged-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\argparse4j-0.7.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\audience-annotations-0.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\commons-cli-1.4.jar;D:\kafka\kafka_2.13-2.5.0\libs\commons-lang3-3.8.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\connect-api-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\connect-basic-auth-extension-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\connect-file-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\connect-json-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\connect-mirror-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\connect-mirror-client-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\connect-runtime-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\connect-transforms-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\hk2-api-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\hk2-locator-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\hk2-utils-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-annotations-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-core-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-databind-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-dataformat-csv-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-datatype-jdk8-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-jaxrs-base-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-module-paranamer-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-module-scala_2.13-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jakarta.activation-api-1.2.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\jakarta.annotation-api-1.3.4.jar;D:\kafka\kafka_2.13-2.5.0\libs\jakarta.inject-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\jakarta.ws.rs-api-2.1.5.jar;D:\kafka\kafka_2.13-2.5.0\libs\jakarta.xml.bind-api-2.3.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\javassist-3.22.0-CR2.jar;D:\kafka\kafka_2.13-2.5.0\libs\javassist-3.26.0-GA.jar;D:\kafka\kafka_2.13-2.5.0\libs\javax.servlet-api-3.1.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\jaxb-api-2.3.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\jersey-client-2.28.jar;D:\kafka\kafka_2.13-2.5.0\libs\jersey-common-2.28.jar;D:\kafka\kafka_2.13-2.5.0\libs\jersey-container-servlet-2.28.jar;D:\kafka\kafka_2.13-2.5.0\libs\jersey-container-servlet-core-2.28.jar;D:\kafka\kafka_2.13-2.5.0\libs\jersey-hk2-2.28.jar;D:\kafka\kafka_2.13-2.5.0\libs\jersey-media-jaxb-2.28.jar;D:\kafka\kafka_2.13-2.5.0\libs\jersey-server-2.28.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-client-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-continuation-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-http-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-io-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-security-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-server-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-servlet-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-servlets-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-util-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jopt-simple-5.0.4.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka_2.13-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka_2.13-2.5.0-sources.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka-clients-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka-log4j-appender-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka-streams-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka-streams-examples-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka-streams-test-utils-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka-tools-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\log4j-1.2.17.jar;D:\kafka\kafka_2.13-2.5.0\libs\lz4-java-1.7.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\maven-artifact-3.6.3.jar;D:\kafka\kafka_2.13-2.5.0\libs\metrics-core-2.2.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\netty-buffer-4.1.45.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\netty-codec-4.1.45.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\netty-common-4.1.45.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\netty-handler-4.1.45.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\netty-resolver-4.1.45.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\netty-transport-4.1.45.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\osgi-resource-locator-1.0.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\paranamer-2.8.jar;D:\kafka\kafka_2.13-2.5.0\libs\plexus-utils-3.2.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\reflections-0.9.12.jar;D:\kafka\kafka_2.13-2.5.0\libs\rocksdbjni-5.18.3.jar;D:\kafka\kafka_2.13-2.5.0\libs\scala-collection-compat_2.13-2.1.3.jar;D:\kafka\kafka_2.13-2.5.0\libs\scala-java8-compat_2.13-0.9.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\scala-library-2.13.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\scala-logging_2.13-3.9.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\scala-reflect-2.13.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\slf4j-api-1.7.30.jar;D:\kafka\kafka_2.13-2.5.0\libs\slf4j-log4j12-1.7.30.jar;D:\kafka\kafka_2.13-2.5.0\libs\snappy-java-1.1.7.3.jar;D:\kafka\kafka_2.13-2.5.0\libs\validation-api-2.0.1.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\zookeeper-3.5.7.jar;D:\kafka\kafka_2.13-2.5.0\libs\zookeeper-jute-3.5.7.jar;D:\kafka\kafka_2.13-2.5.0\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,856] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,857] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,857] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,858] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,858] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,858] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,859] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,859] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,859] INFO Server environment:user.dir=D:\kafka\kafka_2.13-2.5.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,859] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,860] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,860] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,862] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,862] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,863] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:00:01,877] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 19:00:01,880] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:00:01,888] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:00:01,904] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 19:00:01,909] INFO Snapshotting: 0x0 to D:\temp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 19:00:01,913] INFO Snapshotting: 0x0 to D:\temp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 19:00:01,931] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 19:00:39,782] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 19:00:40,106] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 19:00:40,154] INFO starting (kafka.server.KafkaServer)
[2021-04-14 19:00:40,156] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 19:00:40,175] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:00:44,714] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,715] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,716] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,716] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,716] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,717] INFO Client environment:java.class.path=D:\kafka\kafka_2.13-2.5.0\libs\activation-1.1.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\aopalliance-repackaged-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\argparse4j-0.7.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\audience-annotations-0.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\commons-cli-1.4.jar;D:\kafka\kafka_2.13-2.5.0\libs\commons-lang3-3.8.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\connect-api-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\connect-basic-auth-extension-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\connect-file-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\connect-json-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\connect-mirror-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\connect-mirror-client-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\connect-runtime-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\connect-transforms-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\hk2-api-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\hk2-locator-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\hk2-utils-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-annotations-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-core-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-databind-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-dataformat-csv-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-datatype-jdk8-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-jaxrs-base-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-module-paranamer-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jackson-module-scala_2.13-2.10.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\jakarta.activation-api-1.2.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\jakarta.annotation-api-1.3.4.jar;D:\kafka\kafka_2.13-2.5.0\libs\jakarta.inject-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\jakarta.ws.rs-api-2.1.5.jar;D:\kafka\kafka_2.13-2.5.0\libs\jakarta.xml.bind-api-2.3.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\javassist-3.22.0-CR2.jar;D:\kafka\kafka_2.13-2.5.0\libs\javassist-3.26.0-GA.jar;D:\kafka\kafka_2.13-2.5.0\libs\javax.servlet-api-3.1.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\jaxb-api-2.3.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\jersey-client-2.28.jar;D:\kafka\kafka_2.13-2.5.0\libs\jersey-common-2.28.jar;D:\kafka\kafka_2.13-2.5.0\libs\jersey-container-servlet-2.28.jar;D:\kafka\kafka_2.13-2.5.0\libs\jersey-container-servlet-core-2.28.jar;D:\kafka\kafka_2.13-2.5.0\libs\jersey-hk2-2.28.jar;D:\kafka\kafka_2.13-2.5.0\libs\jersey-media-jaxb-2.28.jar;D:\kafka\kafka_2.13-2.5.0\libs\jersey-server-2.28.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-client-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-continuation-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-http-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-io-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-security-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-server-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-servlet-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-servlets-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jetty-util-9.4.24.v20191120.jar;D:\kafka\kafka_2.13-2.5.0\libs\jopt-simple-5.0.4.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka_2.13-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka_2.13-2.5.0-sources.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka-clients-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka-log4j-appender-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka-streams-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka-streams-examples-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka-streams-test-utils-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\kafka-tools-2.5.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\log4j-1.2.17.jar;D:\kafka\kafka_2.13-2.5.0\libs\lz4-java-1.7.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\maven-artifact-3.6.3.jar;D:\kafka\kafka_2.13-2.5.0\libs\metrics-core-2.2.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\netty-buffer-4.1.45.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\netty-codec-4.1.45.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\netty-common-4.1.45.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\netty-handler-4.1.45.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\netty-resolver-4.1.45.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\netty-transport-4.1.45.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\osgi-resource-locator-1.0.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\paranamer-2.8.jar;D:\kafka\kafka_2.13-2.5.0\libs\plexus-utils-3.2.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\reflections-0.9.12.jar;D:\kafka\kafka_2.13-2.5.0\libs\rocksdbjni-5.18.3.jar;D:\kafka\kafka_2.13-2.5.0\libs\scala-collection-compat_2.13-2.1.3.jar;D:\kafka\kafka_2.13-2.5.0\libs\scala-java8-compat_2.13-0.9.0.jar;D:\kafka\kafka_2.13-2.5.0\libs\scala-library-2.13.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\scala-logging_2.13-3.9.2.jar;D:\kafka\kafka_2.13-2.5.0\libs\scala-reflect-2.13.1.jar;D:\kafka\kafka_2.13-2.5.0\libs\slf4j-api-1.7.30.jar;D:\kafka\kafka_2.13-2.5.0\libs\slf4j-log4j12-1.7.30.jar;D:\kafka\kafka_2.13-2.5.0\libs\snappy-java-1.1.7.3.jar;D:\kafka\kafka_2.13-2.5.0\libs\validation-api-2.0.1.Final.jar;D:\kafka\kafka_2.13-2.5.0\libs\zookeeper-3.5.7.jar;D:\kafka\kafka_2.13-2.5.0\libs\zookeeper-jute-3.5.7.jar;D:\kafka\kafka_2.13-2.5.0\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,736] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,737] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,738] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,738] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,739] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,739] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,739] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,740] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,740] INFO Client environment:user.dir=D:\kafka\kafka_2.13-2.5.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,740] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,741] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,741] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,744] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:00:44,754] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 19:00:44,761] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:00:44,764] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:00:44,768] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:00:44,770] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:57860, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:00:44,781] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 19:00:44,823] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10004e6de8f0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:00:44,835] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:00:45,362] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 19:00:45,369] WARN No meta.properties file under dir D:\temp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2021-04-14 19:00:45,430] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 19:00:45,484] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 19:00:45,557] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:00:45,557] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:00:45,558] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:00:45,585] INFO Log directory D:\temp\kafka-logs not found, creating it. (kafka.log.LogManager)
[2021-04-14 19:00:45,594] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 19:00:45,603] INFO Logs loading complete in 8 ms. (kafka.log.LogManager)
[2021-04-14 19:00:45,625] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 19:00:45,628] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 19:00:46,028] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 19:00:46,086] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 19:00:46,088] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 19:00:46,109] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:00:46,110] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:00:46,110] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:00:46,111] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:00:46,126] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 19:00:50,681] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 19:00:50,735] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1618437650700,1618437650700,1,0,0,72062983660830720,200,0,24
 (kafka.zk.KafkaZkClient)
[2021-04-14 19:00:50,737] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArraySeq(EndPoint(DESKTOP-N4251U6,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2021-04-14 19:00:50,832] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:00:50,836] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:00:50,837] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:00:50,859] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2021-04-14 19:00:50,870] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 19:00:50,872] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 19:00:50,877] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2021-04-14 19:00:50,905] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-14 19:00:50,933] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 19:00:50,935] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-14 19:00:50,935] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 19:00:50,972] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:00:50,996] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-14 19:00:51,008] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2021-04-14 19:00:51,015] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 19:00:51,015] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 19:00:51,016] INFO Kafka startTimeMs: 1618437651010 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 19:00:51,018] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-04-14 19:10:50,876] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2021-04-14 19:12:10,471] INFO Creating topic twitter with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2021-04-14 19:12:10,547] INFO [KafkaApi-0] Auto creation of topic twitter with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2021-04-14 19:12:10,667] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(twitter-0) (kafka.server.ReplicaFetcherManager)
[2021-04-14 19:12:10,756] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-14 19:12:10,765] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2021-04-14 19:12:10,769] INFO Created log for partition twitter-0 in D:\temp\kafka-logs\twitter-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2021-04-14 19:12:10,772] INFO [Partition twitter-0 broker=0] No checkpointed highwatermark is found for partition twitter-0 (kafka.cluster.Partition)
[2021-04-14 19:12:10,774] INFO [Partition twitter-0 broker=0] Log loaded for partition twitter-0 with initial high watermark 0 (kafka.cluster.Partition)
[2021-04-14 19:12:10,776] INFO [Partition twitter-0 broker=0] twitter-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2021-04-14 19:17:18,472] WARN Session 0x10004e6de8f0000 for server localhost/0:0:0:0:0:0:0:1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Se ha forzado la interrupción de una conexión existente por el host remoto
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(Unknown Source)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(Unknown Source)
	at sun.nio.ch.IOUtil.read(Unknown Source)
	at sun.nio.ch.SocketChannelImpl.read(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:75)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1223)
[2021-04-14 19:17:19,711] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:17:21,113] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 19:17:21,115] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2021-04-14 19:17:21,724] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:17:21,834] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:17:23,025] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:17:25,039] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:17:26,757] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:17:28,796] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:26:46,924] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:26:46,933] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:26:46,934] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:26:46,937] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:26:46,937] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:26:46,937] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:26:46,937] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 19:26:46,939] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 19:26:46,958] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:26:46,958] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:26:46,959] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:26:46,959] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 19:26:46,963] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 19:26:46,981] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 19:26:47,299] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 19:26:47,348] INFO starting (kafka.server.KafkaServer)
[2021-04-14 19:26:47,350] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 19:26:47,369] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:26:51,512] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,513] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,515] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,515] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,516] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,517] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,536] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,538] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,539] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,540] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,540] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,540] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,541] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,542] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,542] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,543] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,544] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,544] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,546] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,547] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,547] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:26:51,562] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 19:26:51,566] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:26:51,574] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:26:51,592] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 19:26:51,600] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 19:26:51,627] INFO Snapshotting: 0x22 to D:\temp\zookeeper\version-2\snapshot.22 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 19:26:51,650] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 19:26:51,902] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,904] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,904] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,905] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,906] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,907] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,923] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,925] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,925] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,926] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,926] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,926] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,927] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,928] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,928] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,928] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,929] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,929] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,932] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:51,943] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 19:26:51,949] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:26:51,953] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:26:51,958] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:26:51,960] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:59712, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:26:51,968] INFO Creating new log file: log.23 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 19:26:52,001] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10004ff6e850000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:26:52,013] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:26:52,389] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 19:26:52,469] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 19:26:52,527] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 19:26:52,607] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:26:52,607] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:26:52,609] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:26:52,647] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 19:26:52,721] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2021-04-14 19:26:52,724] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-14 19:26:52,783] INFO [ProducerStateManager partition=twitter-0] Writing producer snapshot at offset 122 (kafka.log.ProducerStateManager)
[2021-04-14 19:26:52,860] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 122 with message format version 2 (kafka.log.Log)
[2021-04-14 19:26:52,865] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000122.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 19:26:52,876] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 122 in 190 ms (kafka.log.Log)
[2021-04-14 19:26:52,888] INFO Logs loading complete in 240 ms. (kafka.log.LogManager)
[2021-04-14 19:26:52,900] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 19:26:52,902] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 19:26:53,301] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 19:26:53,347] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 19:26:53,349] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 19:26:53,369] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:26:53,370] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:26:53,370] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:26:53,371] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:26:53,386] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 19:26:57,987] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 19:26:58,036] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72062983660830720' does not match current session '72063089155309568' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2021-04-14 19:26:58,045] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1819)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1757)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1724)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:95)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:273)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:82)
	at kafka.Kafka.main(Kafka.scala)
[2021-04-14 19:26:58,050] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 19:26:58,052] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-04-14 19:26:58,059] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-04-14 19:26:58,062] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-04-14 19:26:58,064] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 19:26:58,065] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 19:26:58,065] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 19:26:58,066] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-04-14 19:26:58,069] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-04-14 19:26:58,070] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 19:26:58,072] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 19:26:58,072] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:26:58,269] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:26:58,269] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:26:58,272] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:26:58,471] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:26:58,471] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:26:58,474] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:26:58,675] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:26:58,675] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:26:58,677] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:26:58,876] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:26:58,876] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:26:58,890] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-04-14 19:26:58,891] INFO Shutting down. (kafka.log.LogManager)
[2021-04-14 19:26:59,005] INFO Shutdown complete. (kafka.log.LogManager)
[2021-04-14 19:26:59,006] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:26:59,124] INFO Session: 0x10004ff6e850000 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:26:59,124] INFO EventThread shut down for session: 0x10004ff6e850000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:26:59,127] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:26:59,129] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:26:59,654] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:26:59,654] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:26:59,655] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:27:00,657] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:27:00,657] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:27:00,658] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:27:01,662] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:27:01,662] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:27:01,665] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-04-14 19:27:01,698] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2021-04-14 19:27:01,704] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-14 19:27:01,705] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2021-04-14 19:27:01,706] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 19:27:10,798] INFO Expiring session 0x10004e6de8f0000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:42,181] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:27:42,189] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:27:42,189] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:27:42,191] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:27:42,192] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:27:42,192] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:27:42,192] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 19:27:42,194] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 19:27:42,210] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:27:42,211] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:27:42,211] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:27:42,211] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 19:27:42,214] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 19:27:46,758] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,759] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,759] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,759] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,760] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,760] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,780] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,782] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,783] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,783] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,784] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,784] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,784] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,785] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,785] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,786] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,786] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,786] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,788] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,789] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,790] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:27:46,805] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 19:27:46,808] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:27:46,816] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:27:46,818] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Unknown Source)
	at sun.nio.ch.Net.bind(Unknown Source)
	at sun.nio.ch.ServerSocketChannelImpl.bind(Unknown Source)
	at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:687)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:143)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:106)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:64)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:128)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:82)
[2021-04-14 19:27:59,200] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 19:27:59,516] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 19:27:59,566] INFO starting (kafka.server.KafkaServer)
[2021-04-14 19:27:59,567] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 19:27:59,587] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:28:01,225] INFO shutting down (kafka.server.KafkaServer)
[2021-04-14 19:28:01,233] ERROR Fatal error during KafkaServer shutdown. (kafka.server.KafkaServer)
java.lang.IllegalStateException: Kafka server is still starting up, cannot shut down!
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:602)
	at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:54)
	at kafka.Kafka$.$anonfun$main$3(Kafka.scala:80)
	at kafka.utils.Exit$.$anonfun$addShutdownHook$1(Exit.scala:38)
	at java.lang.Thread.run(Unknown Source)
[2021-04-14 19:28:01,239] ERROR Halting Kafka. (kafka.server.KafkaServerStartable)
[2021-04-14 19:28:54,690] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:28:54,692] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:28:54,696] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:28:54,697] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:28:54,698] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:28:54,698] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:28:54,699] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:28:54,699] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 19:28:54,700] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 19:28:54,714] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:28:54,714] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:28:54,715] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:28:54,715] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:28:54,716] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 19:28:54,719] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 19:28:59,260] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,262] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,263] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,264] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,265] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,266] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,288] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,292] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,292] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,293] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,293] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,293] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,294] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,294] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,295] INFO Server environment:user.dir=D:\streaming_bigdata\kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,295] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,296] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,296] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,298] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,298] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,299] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:28:59,313] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 19:28:59,316] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:28:59,324] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:28:59,340] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 19:28:59,348] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.22 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 19:28:59,373] INFO Snapshotting: 0x33 to D:\temp\zookeeper\version-2\snapshot.33 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 19:28:59,390] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 19:29:57,475] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:29:57,482] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:29:57,482] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:29:57,484] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:29:57,484] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:29:57,484] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:29:57,484] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 19:29:57,486] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 19:29:57,499] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:29:57,500] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:29:57,500] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:29:57,500] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 19:29:57,503] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 19:30:02,035] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,036] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,036] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,037] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,037] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,038] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,049] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,051] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,052] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,052] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,053] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,053] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,054] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,054] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,054] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,055] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,055] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,056] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,058] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,058] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,060] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:30:02,073] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 19:30:02,077] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:30:02,085] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:30:02,103] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 19:30:02,113] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.33 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 19:30:02,126] INFO Snapshotting: 0x33 to D:\temp\zookeeper\version-2\snapshot.33 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 19:30:02,153] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 19:32:34,382] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 19:32:34,716] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 19:32:34,765] INFO starting (kafka.server.KafkaServer)
[2021-04-14 19:32:34,767] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 19:32:34,786] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:32:39,316] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,317] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,317] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,318] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,319] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,319] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,337] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,340] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,340] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,341] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,341] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,342] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,342] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,343] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,343] INFO Client environment:user.dir=D:\streaming_bigdata\kafka (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,343] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,344] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,344] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,347] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:32:39,358] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 19:32:39,365] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:32:39,368] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:32:39,372] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:32:39,374] INFO Socket connection established, initiating session, client: /127.0.0.1:60139, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:32:39,382] INFO Creating new log file: log.34 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 19:32:39,413] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100050256a90000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:32:39,424] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:32:39,786] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 19:32:39,866] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 19:32:39,924] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 19:32:40,002] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:32:40,003] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:32:40,002] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:32:40,043] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 19:32:40,171] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 122 with message format version 2 (kafka.log.Log)
[2021-04-14 19:32:40,188] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000122.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 19:32:40,195] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 122 in 117 ms (kafka.log.Log)
[2021-04-14 19:32:40,208] INFO Logs loading complete in 165 ms. (kafka.log.LogManager)
[2021-04-14 19:32:40,222] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 19:32:40,223] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 19:32:40,612] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 19:32:40,657] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 19:32:40,659] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 19:32:40,680] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:32:40,680] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:32:40,681] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:32:40,682] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:32:40,696] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 19:32:45,292] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 19:32:45,341] INFO Stat of the created znode at /brokers/ids/0 is: 66,66,1618439565307,1618439565307,1,0,0,72063101639917568,200,0,66
 (kafka.zk.KafkaZkClient)
[2021-04-14 19:32:45,343] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArraySeq(EndPoint(DESKTOP-N4251U6,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 66 (kafka.zk.KafkaZkClient)
[2021-04-14 19:32:45,430] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:32:45,435] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:32:45,436] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:32:45,475] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 19:32:45,477] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 19:32:45,483] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2021-04-14 19:32:45,500] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-14 19:32:45,530] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 19:32:45,533] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-14 19:32:45,533] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 19:32:45,567] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:32:45,590] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-14 19:32:45,647] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2021-04-14 19:32:45,657] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 19:32:45,664] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 19:32:45,665] INFO Kafka startTimeMs: 1618439565649 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 19:32:45,669] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-04-14 19:32:45,733] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(twitter-0) (kafka.server.ReplicaFetcherManager)
[2021-04-14 19:32:45,744] INFO [Partition twitter-0 broker=0] Log loaded for partition twitter-0 with initial high watermark 122 (kafka.cluster.Partition)
[2021-04-14 19:32:45,747] INFO [Partition twitter-0 broker=0] twitter-0 starts at leader epoch 0 from offset 122 with high watermark 122. Previous leader epoch was -1. (kafka.cluster.Partition)
[2021-04-14 19:42:45,484] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2021-04-14 19:44:38,596] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:44:38,603] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:44:38,603] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:44:38,604] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:44:38,605] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:44:38,605] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:44:38,605] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 19:44:38,606] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 19:44:38,620] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:44:38,621] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:44:38,621] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:44:38,621] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 19:44:38,624] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 19:44:43,164] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,165] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,165] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,166] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,166] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,167] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,171] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,171] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,172] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,172] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,172] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,173] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,173] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,173] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,174] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,174] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,174] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,174] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,177] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,178] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,179] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:44:43,193] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 19:44:43,198] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:44:43,208] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:44:43,210] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Unknown Source)
	at sun.nio.ch.Net.bind(Unknown Source)
	at sun.nio.ch.ServerSocketChannelImpl.bind(Unknown Source)
	at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:687)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:143)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:106)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:64)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:128)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:82)
[2021-04-14 19:44:49,880] WARN Session 0x100050256a90000 for server localhost/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Se ha forzado la interrupción de una conexión existente por el host remoto
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(Unknown Source)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(Unknown Source)
	at sun.nio.ch.IOUtil.read(Unknown Source)
	at sun.nio.ch.SocketChannelImpl.read(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:75)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1223)
[2021-04-14 19:44:51,546] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:44:53,570] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:44:55,118] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:44:57,147] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:44:58,379] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:00,387] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:02,232] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:02,729] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 19:45:03,119] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 19:45:03,177] INFO starting (kafka.server.KafkaServer)
[2021-04-14 19:45:03,179] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 19:45:03,201] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:45:04,254] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:05,626] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:07,655] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:07,748] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,748] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,749] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,749] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,749] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,750] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,752] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,753] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,753] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,753] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,753] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,754] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,754] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,754] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,754] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,754] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,755] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,755] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,758] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:07,768] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 19:45:07,777] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:07,779] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:45:07,783] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:08,052] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:45:08,059] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:45:08,060] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:45:08,062] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:45:08,062] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:45:08,063] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:45:08,063] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 19:45:08,065] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 19:45:08,081] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:45:08,082] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:45:08,082] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:45:08,083] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 19:45:08,085] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 19:45:09,138] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:09,832] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:10,948] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:11,168] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:12,637] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,638] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,638] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,639] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,639] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,640] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,645] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,646] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,646] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,647] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,647] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,647] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,648] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,648] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,648] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,649] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,649] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,650] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,652] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,652] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,654] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:45:12,669] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 19:45:12,673] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:45:12,681] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:45:12,703] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 19:45:12,715] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.33 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 19:45:12,747] INFO Snapshotting: 0x45 to D:\temp\zookeeper\version-2\snapshot.45 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 19:45:12,769] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 19:45:12,983] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:60991, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:12,996] INFO Creating new log file: log.46 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 19:45:13,035] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10005103bc40000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:13,048] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:45:13,088] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:13,089] INFO Socket connection established, initiating session, client: /127.0.0.1:61003, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:13,093] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100050256a90000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:13,428] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 19:45:13,510] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 19:45:13,584] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 19:45:13,676] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:13,676] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:13,678] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:13,714] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in D:\temp\kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:238)
	at scala.collection.StrictOptimizedIterableOps.flatMap(StrictOptimizedIterableOps.scala:118)
	at scala.collection.StrictOptimizedIterableOps.flatMap$(StrictOptimizedIterableOps.scala:105)
	at scala.collection.mutable.ArraySeq.flatMap(ArraySeq.scala:38)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:233)
	at kafka.log.LogManager.<init>(LogManager.scala:104)
	at kafka.log.LogManager$.apply(LogManager.scala:1084)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:253)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:82)
	at kafka.Kafka.main(Kafka.scala)
[2021-04-14 19:45:13,721] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 19:45:13,724] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:45:13,838] INFO Session: 0x10005103bc40000 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:13,838] INFO EventThread shut down for session: 0x10005103bc40000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:13,840] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:45:13,842] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:14,682] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:14,682] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:14,684] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:15,692] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:15,692] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:15,692] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:16,707] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:16,707] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:16,721] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-14 19:45:16,723] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2021-04-14 19:45:16,724] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 19:45:37,189] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 19:45:37,190] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2021-04-14 19:45:37,209] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2021-04-14 19:45:37,212] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-14 19:45:37,213] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-14 19:45:37,213] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-14 19:45:37,214] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-04-14 19:45:37,224] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-04-14 19:45:37,225] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2021-04-14 19:45:37,228] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2021-04-14 19:45:37,232] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:37,404] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:37,404] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:37,405] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2021-04-14 19:45:37,406] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:37,606] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:37,606] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:37,609] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 19:45:37,610] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 1000 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-14 19:45:37,611] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2021-04-14 19:45:37,611] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-14 19:45:37,612] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-14 19:45:37,612] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-14 19:45:37,614] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 19:45:37,615] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 19:45:37,616] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:37,807] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:37,807] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:37,807] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:38,010] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:38,010] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:38,011] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 19:45:38,013] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-04-14 19:45:38,014] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 19:45:38,015] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 19:45:38,015] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 19:45:38,016] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-04-14 19:45:38,019] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-04-14 19:45:38,020] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 19:45:38,020] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 19:45:38,021] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:38,213] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:38,213] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:38,214] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:38,414] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:38,414] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:38,415] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:38,618] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:38,618] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:38,618] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:38,822] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:38,822] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 19:45:38,859] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-04-14 19:45:38,860] INFO Shutting down. (kafka.log.LogManager)
[2021-04-14 19:45:38,889] INFO [ProducerStateManager partition=twitter-0] Writing producer snapshot at offset 125 (kafka.log.ProducerStateManager)
[2021-04-14 19:45:38,969] INFO Shutdown complete. (kafka.log.LogManager)
[2021-04-14 19:45:38,976] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:45:39,104] INFO Session: 0x100050256a90000 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:45:39,104] INFO EventThread shut down for session: 0x100050256a90000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:45:39,105] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:45:39,106] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:40,019] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:40,019] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:40,019] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:41,031] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:41,031] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:41,032] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:42,043] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:42,043] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 19:45:42,044] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-04-14 19:45:42,073] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2021-04-14 19:45:42,078] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-14 19:47:18,371] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:47:18,378] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:47:18,378] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:47:18,380] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:47:18,380] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:47:18,380] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:47:18,381] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 19:47:18,382] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 19:47:18,395] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:47:18,396] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:47:18,396] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:47:18,396] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 19:47:18,399] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 19:47:22,926] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,927] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,927] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,927] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,928] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,928] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,931] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,932] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,932] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,932] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,932] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,932] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,933] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,933] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,933] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,934] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,934] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,934] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,937] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,938] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,940] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:47:22,952] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 19:47:22,955] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:47:22,966] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:47:22,984] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 19:47:22,994] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.45 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 19:47:23,020] INFO Snapshotting: 0x55 to D:\temp\zookeeper\version-2\snapshot.55 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 19:47:23,043] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 19:47:59,289] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 19:48:17,937] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:48:17,943] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:48:17,943] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:48:17,944] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:48:17,944] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:48:17,945] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 19:48:17,945] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 19:48:17,946] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 19:48:17,961] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:48:17,961] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:48:17,961] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 19:48:17,961] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 19:48:17,964] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 19:48:22,511] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,511] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,511] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,511] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,511] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,512] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,513] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,513] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,513] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,513] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,513] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,513] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,513] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,513] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,513] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,514] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,514] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,514] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,516] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,516] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,517] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 19:48:22,531] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 19:48:22,533] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:48:22,541] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 19:48:22,557] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 19:48:22,566] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.55 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 19:48:22,578] INFO Snapshotting: 0x55 to D:\temp\zookeeper\version-2\snapshot.55 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 19:48:22,599] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 19:55:32,748] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 19:55:33,074] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 19:55:33,123] INFO starting (kafka.server.KafkaServer)
[2021-04-14 19:55:33,124] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 19:55:33,145] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:55:37,682] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,683] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,683] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,683] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,684] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,685] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,699] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,703] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,704] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,704] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,704] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,706] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,707] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,707] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,708] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,709] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,709] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,710] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,716] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 19:55:37,733] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 19:55:37,743] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:55:37,747] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 19:55:37,755] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:55:39,786] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:55:40,904] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 19:55:41,828] INFO shutting down (kafka.server.KafkaServer)
[2021-04-14 19:55:41,833] ERROR Fatal error during KafkaServer shutdown. (kafka.server.KafkaServer)
java.lang.IllegalStateException: Kafka server is still starting up, cannot shut down!
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:602)
	at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:54)
	at kafka.Kafka$.$anonfun$main$3(Kafka.scala:80)
	at kafka.utils.Exit$.$anonfun$addShutdownHook$1(Exit.scala:38)
	at java.lang.Thread.run(Unknown Source)
[2021-04-14 19:55:41,837] ERROR Halting Kafka. (kafka.server.KafkaServerStartable)
[2021-04-14 20:02:03,037] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 20:02:03,042] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:02:03,054] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:02:03,055] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:02:03,059] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:02:03,059] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:02:03,060] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:02:03,060] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:02:03,064] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:02:03,088] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:02:03,090] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:02:03,090] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:02:03,091] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:02:03,095] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:02:03,393] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 20:02:03,459] INFO starting (kafka.server.KafkaServer)
[2021-04-14 20:02:03,460] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 20:02:03,480] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:02:07,641] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,643] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,644] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,645] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,646] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,647] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,663] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,665] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,666] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,666] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,666] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,667] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,667] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,667] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,668] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,668] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,668] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,669] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,671] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,671] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,672] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:02:07,686] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:02:07,690] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:02:07,699] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:02:07,700] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Unknown Source)
	at sun.nio.ch.Net.bind(Unknown Source)
	at sun.nio.ch.ServerSocketChannelImpl.bind(Unknown Source)
	at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:687)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:143)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:106)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:64)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:128)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:82)
[2021-04-14 20:02:08,014] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,016] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,018] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,018] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,019] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,021] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,038] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,040] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,041] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,041] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,041] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,042] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,042] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,042] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,043] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,043] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,043] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,043] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,047] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:02:08,057] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 20:02:08,065] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:02:08,068] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:02:08,072] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:02:08,074] INFO Socket connection established, initiating session, client: /127.0.0.1:62235, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:02:08,106] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100051c18960001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:02:08,119] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:02:08,478] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 20:02:08,559] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:02:08,617] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:02:08,697] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:02:08,698] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:02:08,700] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:02:08,739] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 20:02:08,863] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 125 with message format version 2 (kafka.log.Log)
[2021-04-14 20:02:08,879] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000125.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 20:02:08,886] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 125 in 116 ms (kafka.log.Log)
[2021-04-14 20:02:08,900] INFO Logs loading complete in 161 ms. (kafka.log.LogManager)
[2021-04-14 20:02:08,913] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 20:02:08,915] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 20:02:09,308] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 20:02:09,354] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 20:02:09,355] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 20:02:09,377] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:02:09,377] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:02:09,379] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:02:09,379] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:02:09,394] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:02:13,994] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 20:02:14,034] INFO Stat of the created znode at /brokers/ids/0 is: 135,135,1618441334005,1618441334005,1,0,0,72063212267634689,200,0,135
 (kafka.zk.KafkaZkClient)
[2021-04-14 20:02:14,036] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArraySeq(EndPoint(DESKTOP-N4251U6,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 135 (kafka.zk.KafkaZkClient)
[2021-04-14 20:02:14,130] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:02:14,135] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:02:14,136] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:02:14,159] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 20:02:14,161] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 20:02:14,169] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2021-04-14 20:02:14,188] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-14 20:02:14,220] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 20:02:14,223] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-14 20:02:14,223] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 20:02:14,255] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:02:14,282] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-14 20:02:14,309] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2021-04-14 20:02:14,324] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:02:14,325] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:02:14,326] INFO Kafka startTimeMs: 1618441334310 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:02:14,328] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-04-14 20:02:14,423] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(twitter-0) (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:02:14,434] INFO [Partition twitter-0 broker=0] Log loaded for partition twitter-0 with initial high watermark 125 (kafka.cluster.Partition)
[2021-04-14 20:02:14,436] INFO [Partition twitter-0 broker=0] twitter-0 starts at leader epoch 0 from offset 125 with high watermark 125. Previous leader epoch was -1. (kafka.cluster.Partition)
[2021-04-14 20:03:03,828] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:03:03,830] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2021-04-14 20:03:04,158] WARN Session 0x100051c18960001 for server localhost/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Se ha forzado la interrupción de una conexión existente por el host remoto
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(Unknown Source)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(Unknown Source)
	at sun.nio.ch.IOUtil.read(Unknown Source)
	at sun.nio.ch.SocketChannelImpl.read(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:75)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1223)
[2021-04-14 20:03:04,281] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:03:04,282] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:03:06,057] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:03:08,105] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:03:08,214] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:03:09,638] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:03:11,678] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:03:13,091] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:03:15,124] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:03:16,742] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:04:25,402] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:04:25,411] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:04:25,412] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:04:25,415] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:04:25,415] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:04:25,415] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:04:25,416] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:04:25,418] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:04:25,435] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:04:25,436] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:04:25,436] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:04:25,436] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:04:25,439] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:04:25,454] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 20:04:25,790] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 20:04:25,840] INFO starting (kafka.server.KafkaServer)
[2021-04-14 20:04:25,842] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 20:04:25,861] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:04:29,995] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:29,997] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:29,999] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,000] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,002] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,003] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,016] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,017] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,018] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,018] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,019] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,019] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,019] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,020] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,020] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,020] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,021] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,021] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,023] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,024] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,024] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:04:30,040] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:04:30,043] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:04:30,052] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:04:30,069] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 20:04:30,080] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.67 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 20:04:30,111] INFO Snapshotting: 0x8a to D:\temp\zookeeper\version-2\snapshot.8a (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:04:30,133] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 20:04:30,399] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,401] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,402] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,403] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,404] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,406] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,421] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,423] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,423] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,424] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,424] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,424] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,425] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,425] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,425] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,426] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,426] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,426] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,429] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:30,440] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 20:04:30,447] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:04:30,451] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:04:30,456] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:04:30,458] INFO Socket connection established, initiating session, client: /127.0.0.1:62424, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:04:30,467] INFO Creating new log file: log.8b (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 20:04:30,500] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000521e4b80000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:04:30,511] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:04:30,890] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 20:04:30,975] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:04:31,035] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:04:31,115] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:04:31,115] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:04:31,117] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:04:31,155] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 20:04:31,217] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2021-04-14 20:04:31,220] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-14 20:04:31,287] INFO [ProducerStateManager partition=twitter-0] Writing producer snapshot at offset 137 (kafka.log.ProducerStateManager)
[2021-04-14 20:04:31,351] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 137 with message format version 2 (kafka.log.Log)
[2021-04-14 20:04:31,353] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000137.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 20:04:31,357] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 137 in 173 ms (kafka.log.Log)
[2021-04-14 20:04:31,369] INFO Logs loading complete in 213 ms. (kafka.log.LogManager)
[2021-04-14 20:04:31,382] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 20:04:31,384] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 20:04:31,785] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 20:04:31,832] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 20:04:31,834] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 20:04:31,857] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:04:31,858] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:04:31,858] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:04:31,860] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:04:31,874] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:04:36,462] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 20:04:36,507] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72063212267634689' does not match current session '72063237167251456' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2021-04-14 20:04:36,516] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1819)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1757)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1724)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:95)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:273)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:82)
	at kafka.Kafka.main(Kafka.scala)
[2021-04-14 20:04:36,522] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:04:36,524] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-04-14 20:04:36,530] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-04-14 20:04:36,533] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-04-14 20:04:36,534] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:04:36,536] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:04:36,536] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:04:36,537] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:04:36,539] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:04:36,541] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 20:04:36,543] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 20:04:36,543] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:04:36,566] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:04:36,566] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:04:36,568] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:04:36,769] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:04:36,769] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:04:36,772] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:04:36,971] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:04:36,971] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:04:36,972] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:04:37,174] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:04:37,174] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:04:37,187] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-04-14 20:04:37,189] INFO Shutting down. (kafka.log.LogManager)
[2021-04-14 20:04:37,307] INFO Shutdown complete. (kafka.log.LogManager)
[2021-04-14 20:04:37,309] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:04:37,441] INFO Session: 0x1000521e4b80000 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:04:37,441] INFO EventThread shut down for session: 0x1000521e4b80000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:04:37,443] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:04:37,444] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:04:38,181] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:04:38,181] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:04:38,183] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:04:39,171] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:04:39,171] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:04:39,174] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:04:39,186] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:04:39,186] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:04:39,192] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-04-14 20:04:39,231] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2021-04-14 20:04:39,238] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-14 20:04:39,239] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2021-04-14 20:04:39,240] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:04:49,798] INFO Expiring session 0x100051c18960001, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:09,473] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:07:09,482] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:07:09,482] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:07:09,485] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:07:09,485] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:07:09,485] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:07:09,486] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:07:09,488] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:07:09,507] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:07:09,508] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:07:09,509] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:07:09,509] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:07:09,514] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:07:09,576] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 20:07:09,912] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 20:07:09,964] INFO starting (kafka.server.KafkaServer)
[2021-04-14 20:07:09,965] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 20:07:09,985] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:07:14,081] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,083] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,085] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,086] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,087] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,088] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,101] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,103] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,104] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,104] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,104] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,105] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,105] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,105] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,106] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,106] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,106] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,107] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,109] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,109] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,110] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:07:14,124] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:07:14,127] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:07:14,136] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:07:14,154] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 20:07:14,166] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.8a (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 20:07:14,195] INFO Snapshotting: 0x9b to D:\temp\zookeeper\version-2\snapshot.9b (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:07:14,220] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 20:07:14,519] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,521] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,521] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,522] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,523] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,524] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,538] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,540] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,540] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,541] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,541] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,541] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,542] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,542] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,542] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,543] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,544] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,544] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,547] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:07:14,558] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 20:07:14,565] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:07:14,568] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:07:14,572] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:07:14,575] INFO Socket connection established, initiating session, client: /127.0.0.1:62618, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:07:14,583] INFO Creating new log file: log.9c (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 20:07:14,613] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100052465ac0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:07:14,626] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:07:15,016] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 20:07:15,096] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:07:15,157] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:07:15,238] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:07:15,238] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:07:15,240] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:07:15,276] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 20:07:15,410] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 137 with message format version 2 (kafka.log.Log)
[2021-04-14 20:07:15,426] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000137.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 20:07:15,432] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 137 in 125 ms (kafka.log.Log)
[2021-04-14 20:07:15,443] INFO Logs loading complete in 167 ms. (kafka.log.LogManager)
[2021-04-14 20:07:15,455] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 20:07:15,456] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 20:07:15,791] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 20:07:15,831] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 20:07:15,832] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 20:07:15,850] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:07:15,851] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:07:15,851] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:07:15,852] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:07:15,866] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:07:20,456] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 20:07:20,492] INFO Stat of the created znode at /brokers/ids/0 is: 170,170,1618441640472,1618441640472,1,0,0,72063247920660480,200,0,170
 (kafka.zk.KafkaZkClient)
[2021-04-14 20:07:20,493] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArraySeq(EndPoint(DESKTOP-N4251U6,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 170 (kafka.zk.KafkaZkClient)
[2021-04-14 20:07:20,576] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:07:20,580] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:07:20,581] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:07:20,600] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 20:07:20,602] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 20:07:20,607] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2021-04-14 20:07:20,631] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:4000,blockEndProducerId:4999) by writing to Zk with path version 5 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-14 20:07:20,660] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 20:07:20,663] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-14 20:07:20,663] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 20:07:20,692] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:07:20,713] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-14 20:07:20,736] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2021-04-14 20:07:20,741] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:07:20,742] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:07:20,742] INFO Kafka startTimeMs: 1618441640737 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:07:20,744] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-04-14 20:07:20,849] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(twitter-0) (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:07:20,861] INFO [Partition twitter-0 broker=0] Log loaded for partition twitter-0 with initial high watermark 137 (kafka.cluster.Partition)
[2021-04-14 20:07:20,864] INFO [Partition twitter-0 broker=0] twitter-0 starts at leader epoch 0 from offset 137 with high watermark 137. Previous leader epoch was -1. (kafka.cluster.Partition)
[2021-04-14 20:08:10,024] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:08:10,026] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2021-04-14 20:08:10,518] WARN Session 0x100052465ac0000 for server localhost/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Se ha forzado la interrupción de una conexión existente por el host remoto
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(Unknown Source)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(Unknown Source)
	at sun.nio.ch.IOUtil.read(Unknown Source)
	at sun.nio.ch.SocketChannelImpl.read(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:75)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1223)
[2021-04-14 20:08:10,645] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:08:10,645] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:08:12,398] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:08:14,440] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:08:14,548] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:08:15,960] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:08:17,966] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:08:19,487] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:08:21,523] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:08:22,944] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:08:25,000] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:08:26,910] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:08:28,931] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:08:30,803] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:08:32,816] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:08:34,611] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:08:36,636] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:08:55,168] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:08:55,175] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:08:55,176] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:08:55,178] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:08:55,178] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:08:55,179] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:08:55,179] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:08:55,181] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:08:55,196] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:08:55,196] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:08:55,197] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:08:55,197] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:08:55,201] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:08:59,742] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,742] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,743] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,743] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,743] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,744] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,755] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,756] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,757] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,757] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,758] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,759] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,760] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,760] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,761] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,762] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,762] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,763] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,765] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,766] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,766] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:08:59,784] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:08:59,787] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:08:59,795] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:08:59,820] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 20:08:59,833] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.9b (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 20:08:59,870] INFO Snapshotting: 0xad to D:\temp\zookeeper\version-2\snapshot.ad (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:08:59,898] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 20:09:07,927] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:09:07,936] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:09:07,937] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:09:07,939] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:09:07,940] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:09:07,940] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:09:07,940] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:09:07,942] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:09:07,959] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:09:07,961] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:09:07,961] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:09:07,962] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:09:07,964] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 20:09:07,966] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:09:08,305] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 20:09:08,357] INFO starting (kafka.server.KafkaServer)
[2021-04-14 20:09:08,358] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 20:09:08,379] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:09:12,495] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,497] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,498] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,499] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,500] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,501] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,512] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,514] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,514] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,514] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,515] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,515] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,515] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,516] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,516] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,516] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,517] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,517] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,519] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,520] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,521] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:12,535] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:09:12,539] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:09:12,547] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:09:12,548] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Unknown Source)
	at sun.nio.ch.Net.bind(Unknown Source)
	at sun.nio.ch.ServerSocketChannelImpl.bind(Unknown Source)
	at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:687)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:143)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:106)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:64)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:128)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:82)
[2021-04-14 20:09:12,898] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,899] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,900] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,900] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,901] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,902] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,913] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,915] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,916] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,916] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,916] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,917] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,917] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,918] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,918] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,918] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,919] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,919] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,922] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:12,932] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 20:09:12,940] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:09:12,943] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:09:12,947] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:09:12,950] INFO Socket connection established, initiating session, client: /127.0.0.1:62784, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:09:12,958] INFO Creating new log file: log.ae (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 20:09:12,990] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100052602770000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:09:13,002] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:09:13,404] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 20:09:13,488] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:09:13,548] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:09:13,629] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:09:13,629] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:09:13,632] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:09:13,670] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 20:09:13,736] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2021-04-14 20:09:13,739] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-14 20:09:13,800] INFO [ProducerStateManager partition=twitter-0] Writing producer snapshot at offset 139 (kafka.log.ProducerStateManager)
[2021-04-14 20:09:13,862] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 139 with message format version 2 (kafka.log.Log)
[2021-04-14 20:09:13,864] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000139.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 20:09:13,868] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 139 in 167 ms (kafka.log.Log)
[2021-04-14 20:09:13,880] INFO Logs loading complete in 209 ms. (kafka.log.LogManager)
[2021-04-14 20:09:13,893] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 20:09:13,894] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 20:09:14,293] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 20:09:14,341] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 20:09:14,344] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 20:09:14,365] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:09:14,365] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:09:14,366] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:09:14,366] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:09:14,382] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:09:18,970] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 20:09:19,018] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72063247920660480' does not match current session '72063254846177280' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2021-04-14 20:09:19,027] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1819)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1757)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1724)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:95)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:273)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:82)
	at kafka.Kafka.main(Kafka.scala)
[2021-04-14 20:09:19,033] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:09:19,034] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-04-14 20:09:19,041] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-04-14 20:09:19,045] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-04-14 20:09:19,046] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:09:19,047] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:09:19,047] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:09:19,049] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:09:19,050] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:09:19,052] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 20:09:19,054] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 20:09:19,055] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:09:19,082] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:09:19,082] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:09:19,084] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:09:19,289] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:09:19,289] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:09:19,290] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:09:19,504] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:09:19,504] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:09:19,507] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:09:19,706] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:09:19,706] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:09:19,719] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-04-14 20:09:19,720] INFO Shutting down. (kafka.log.LogManager)
[2021-04-14 20:09:19,798] INFO Expiring session 0x100052465ac0000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:09:19,845] INFO Shutdown complete. (kafka.log.LogManager)
[2021-04-14 20:09:19,846] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:09:19,980] INFO Session: 0x100052602770000 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:09:19,980] INFO EventThread shut down for session: 0x100052602770000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:09:19,983] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:09:19,984] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:09:20,687] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:09:20,687] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:09:20,688] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:09:21,691] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:09:21,691] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:09:21,692] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:09:22,700] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:09:22,700] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:09:22,705] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-04-14 20:09:22,738] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2021-04-14 20:09:22,744] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-14 20:09:22,745] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2021-04-14 20:09:22,746] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:10:00,686] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:10:00,694] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:10:00,694] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:10:00,696] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:10:00,696] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:10:00,697] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:10:00,697] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:10:00,699] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:10:00,715] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:10:00,716] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:10:00,716] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:10:00,716] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:10:00,720] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:10:00,817] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 20:10:01,139] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 20:10:01,190] INFO starting (kafka.server.KafkaServer)
[2021-04-14 20:10:01,191] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 20:10:01,211] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:10:05,263] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,264] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,265] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,265] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,266] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,267] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,278] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,280] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,281] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,281] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,281] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,282] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,282] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,282] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,283] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,283] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,283] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,284] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,286] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,286] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,287] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:10:05,301] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:10:05,305] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:10:05,314] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:10:05,315] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Unknown Source)
	at sun.nio.ch.Net.bind(Unknown Source)
	at sun.nio.ch.ServerSocketChannelImpl.bind(Unknown Source)
	at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:687)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:143)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:106)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:64)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:128)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:82)
[2021-04-14 20:10:05,747] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,748] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,749] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,750] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,750] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,752] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,770] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,772] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,772] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,773] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,773] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,773] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,774] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,774] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,774] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,775] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,775] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,775] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,779] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:10:05,791] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 20:10:05,799] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:10:05,802] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:10:05,806] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:10:05,808] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:62861, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:10:05,838] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100052602770001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:10:05,851] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:10:06,220] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 20:10:06,300] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:10:06,358] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:10:06,438] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:10:06,438] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:10:06,441] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:10:06,480] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 20:10:06,626] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 139 with message format version 2 (kafka.log.Log)
[2021-04-14 20:10:06,647] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000139.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 20:10:06,654] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 139 in 139 ms (kafka.log.Log)
[2021-04-14 20:10:06,668] INFO Logs loading complete in 188 ms. (kafka.log.LogManager)
[2021-04-14 20:10:06,681] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 20:10:06,683] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 20:10:07,080] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 20:10:07,128] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 20:10:07,129] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 20:10:07,151] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:10:07,152] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:10:07,153] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:10:07,153] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:10:07,169] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:10:11,761] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 20:10:11,809] INFO Stat of the created znode at /brokers/ids/0 is: 205,205,1618441811774,1618441811774,1,0,0,72063254846177281,200,0,205
 (kafka.zk.KafkaZkClient)
[2021-04-14 20:10:11,811] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArraySeq(EndPoint(DESKTOP-N4251U6,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 205 (kafka.zk.KafkaZkClient)
[2021-04-14 20:10:11,901] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:10:11,905] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:10:11,906] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:10:11,937] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 20:10:11,939] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 20:10:11,945] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2021-04-14 20:10:11,963] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:5000,blockEndProducerId:5999) by writing to Zk with path version 6 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-14 20:10:11,993] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 20:10:11,995] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-14 20:10:11,995] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 20:10:12,021] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:10:12,042] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-14 20:10:12,092] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2021-04-14 20:10:12,104] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:10:12,112] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:10:12,113] INFO Kafka startTimeMs: 1618441812095 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:10:12,116] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-04-14 20:10:12,168] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(twitter-0) (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:10:12,179] INFO [Partition twitter-0 broker=0] Log loaded for partition twitter-0 with initial high watermark 139 (kafka.cluster.Partition)
[2021-04-14 20:10:12,181] INFO [Partition twitter-0 broker=0] twitter-0 starts at leader epoch 0 from offset 139 with high watermark 139. Previous leader epoch was -1. (kafka.cluster.Partition)
[2021-04-14 20:11:48,692] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:11:48,695] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2021-04-14 20:11:49,024] WARN Session 0x100052602770001 for server localhost/0:0:0:0:0:0:0:1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Se ha forzado la interrupción de una conexión existente por el host remoto
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(Unknown Source)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(Unknown Source)
	at sun.nio.ch.IOUtil.read(Unknown Source)
	at sun.nio.ch.SocketChannelImpl.read(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:75)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1223)
[2021-04-14 20:11:49,139] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:11:49,140] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:11:50,276] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:11:52,301] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:11:52,411] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:11:53,847] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:11:55,867] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:11:57,268] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:12:30,643] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:12:30,654] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:12:30,654] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:12:30,659] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:12:30,659] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:12:30,662] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:12:30,663] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:12:30,683] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:12:30,721] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:12:30,722] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:12:30,723] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:12:30,723] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:12:30,726] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:12:30,763] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 20:12:31,135] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 20:12:31,191] INFO starting (kafka.server.KafkaServer)
[2021-04-14 20:12:31,193] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 20:12:31,215] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:12:35,258] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,259] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,259] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,260] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,260] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,261] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,273] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,275] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,276] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,276] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,276] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,277] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,277] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,277] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,278] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,278] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,279] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,279] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,281] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,282] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,282] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:12:35,296] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:12:35,300] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:12:35,308] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:12:35,331] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 20:12:35,344] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.ad (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 20:12:35,377] INFO Snapshotting: 0xd0 to D:\temp\zookeeper\version-2\snapshot.d0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:12:35,405] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 20:12:35,747] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,748] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,749] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,749] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,750] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,751] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,760] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,762] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,762] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,763] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,763] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,764] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,764] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,765] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,765] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,765] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,766] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,766] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,769] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:12:35,779] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 20:12:35,786] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:12:35,789] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:12:35,792] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:12:35,795] INFO Socket connection established, initiating session, client: /127.0.0.1:63049, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:12:35,803] INFO Creating new log file: log.d1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 20:12:35,848] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005294c4d0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:12:35,861] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:12:36,244] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 20:12:36,333] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:12:36,398] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:12:36,468] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:12:36,468] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:12:36,469] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:12:36,500] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 20:12:36,551] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2021-04-14 20:12:36,552] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-14 20:12:36,608] INFO [ProducerStateManager partition=twitter-0] Writing producer snapshot at offset 139 (kafka.log.ProducerStateManager)
[2021-04-14 20:12:36,679] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 139 with message format version 2 (kafka.log.Log)
[2021-04-14 20:12:36,681] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000139.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 20:12:36,686] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 139 in 162 ms (kafka.log.Log)
[2021-04-14 20:12:36,697] INFO Logs loading complete in 197 ms. (kafka.log.LogManager)
[2021-04-14 20:12:36,710] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 20:12:36,711] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 20:12:37,095] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 20:12:37,142] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 20:12:37,144] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 20:12:37,164] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:12:37,165] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:12:37,166] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:12:37,166] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:12:37,180] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:12:41,474] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:12:41,480] ERROR [KafkaServer id=0] Fatal error during KafkaServer shutdown. (kafka.server.KafkaServer)
java.lang.IllegalStateException: Kafka server is still starting up, cannot shut down!
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:602)
	at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:54)
	at kafka.Kafka$.$anonfun$main$3(Kafka.scala:80)
	at kafka.utils.Exit$.$anonfun$addShutdownHook$1(Exit.scala:38)
	at java.lang.Thread.run(Unknown Source)
[2021-04-14 20:12:41,486] ERROR Halting Kafka. (kafka.server.KafkaServerStartable)
[2021-04-14 20:13:04,275] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:13:04,283] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:13:04,284] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:13:04,286] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:13:04,286] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:13:04,287] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:13:04,287] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:13:04,288] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:13:04,303] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:13:04,304] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:13:04,304] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:13:04,305] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:13:04,308] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:13:04,401] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 20:13:04,723] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 20:13:04,773] INFO starting (kafka.server.KafkaServer)
[2021-04-14 20:13:04,774] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 20:13:04,794] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:13:08,863] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,865] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,866] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,867] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,868] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,869] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,889] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,891] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,891] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,892] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,893] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,893] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,894] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,894] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,895] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,895] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,895] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,896] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,898] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,899] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,900] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:08,913] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:13:08,917] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:13:08,924] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:13:08,940] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 20:13:08,950] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.d0 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 20:13:08,972] INFO Snapshotting: 0xde to D:\temp\zookeeper\version-2\snapshot.de (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:13:08,989] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 20:13:09,319] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,320] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,320] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,321] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,321] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,321] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,332] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,333] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,334] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,334] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,334] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,335] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,335] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,335] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,336] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,336] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,336] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,337] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,340] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:09,350] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 20:13:09,356] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:13:09,359] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:13:09,363] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:13:09,366] INFO Socket connection established, initiating session, client: /127.0.0.1:63107, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:13:09,373] INFO Creating new log file: log.df (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 20:13:09,411] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000529cf840000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:13:09,423] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:13:09,814] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 20:13:09,894] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:13:09,949] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:13:10,022] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:10,022] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:10,024] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:10,062] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 20:13:10,124] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2021-04-14 20:13:10,126] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-14 20:13:10,186] INFO [ProducerStateManager partition=twitter-0] Writing producer snapshot at offset 139 (kafka.log.ProducerStateManager)
[2021-04-14 20:13:10,247] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 139 with message format version 2 (kafka.log.Log)
[2021-04-14 20:13:10,250] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000139.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 20:13:10,255] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 139 in 166 ms (kafka.log.Log)
[2021-04-14 20:13:10,267] INFO Logs loading complete in 204 ms. (kafka.log.LogManager)
[2021-04-14 20:13:10,281] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 20:13:10,282] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 20:13:10,677] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 20:13:10,728] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 20:13:10,730] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 20:13:10,752] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:10,753] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:10,753] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:10,754] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:10,769] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:13:15,387] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 20:13:15,440] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72063254846177281' does not match current session '72063271171260416' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2021-04-14 20:13:15,448] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1819)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1757)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1724)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:95)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:273)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:82)
	at kafka.Kafka.main(Kafka.scala)
[2021-04-14 20:13:15,454] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:13:15,456] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-04-14 20:13:15,462] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-04-14 20:13:15,466] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-04-14 20:13:15,467] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:13:15,468] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:13:15,468] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:13:15,470] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:13:15,472] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:13:15,474] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 20:13:15,475] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 20:13:15,477] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:15,659] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:15,659] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:15,660] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:15,860] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:15,860] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:15,861] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:16,064] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:16,064] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:16,065] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:16,269] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:16,269] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:16,276] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-04-14 20:13:16,277] INFO Shutting down. (kafka.log.LogManager)
[2021-04-14 20:13:16,383] INFO Shutdown complete. (kafka.log.LogManager)
[2021-04-14 20:13:16,385] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:13:16,504] INFO Session: 0x1000529cf840000 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:16,504] INFO EventThread shut down for session: 0x1000529cf840000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:13:16,507] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:13:16,509] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:17,079] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:17,079] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:17,080] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:18,081] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:18,081] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:18,082] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:18,097] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:18,097] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:18,100] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-04-14 20:13:18,135] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2021-04-14 20:13:18,143] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-14 20:13:18,144] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2021-04-14 20:13:18,145] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:13:38,163] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 20:13:38,169] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:13:38,177] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:13:38,177] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:13:38,180] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:13:38,180] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:13:38,181] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:13:38,181] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:13:38,183] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:13:38,202] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:13:38,203] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:13:38,203] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:13:38,203] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:13:38,206] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:13:38,506] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 20:13:38,556] INFO starting (kafka.server.KafkaServer)
[2021-04-14 20:13:38,557] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 20:13:38,576] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:13:42,745] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,746] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,746] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,747] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,747] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,748] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,758] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,759] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,760] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,760] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,761] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,761] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,762] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,762] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,763] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,764] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,764] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,764] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,766] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,767] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,767] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:13:42,781] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:13:42,785] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:13:42,793] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:13:42,812] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 20:13:42,825] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.de (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 20:13:42,850] INFO Snapshotting: 0xee to D:\temp\zookeeper\version-2\snapshot.ee (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:13:42,876] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 20:13:43,104] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,106] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,107] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,107] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,108] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,109] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,124] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,126] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,127] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,127] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,128] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,128] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,128] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,129] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,129] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,129] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,130] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,130] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,133] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:43,143] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 20:13:43,150] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:13:43,152] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:13:43,156] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:13:43,159] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:63165, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:13:43,169] INFO Creating new log file: log.ef (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 20:13:43,200] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100052a53dd0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:13:43,212] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:13:43,595] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 20:13:43,674] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:13:43,732] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:13:43,816] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:43,817] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:43,818] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:43,858] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 20:13:43,994] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 139 with message format version 2 (kafka.log.Log)
[2021-04-14 20:13:44,011] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000139.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 20:13:44,018] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 139 in 132 ms (kafka.log.Log)
[2021-04-14 20:13:44,030] INFO Logs loading complete in 172 ms. (kafka.log.LogManager)
[2021-04-14 20:13:44,043] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 20:13:44,045] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 20:13:44,409] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 20:13:44,448] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 20:13:44,449] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 20:13:44,468] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:44,469] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:44,470] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:44,471] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:44,484] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:13:49,096] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 20:13:49,131] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72063254846177281' does not match current session '72063273391685632' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2021-04-14 20:13:49,139] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1819)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1757)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1724)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:95)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:273)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:82)
	at kafka.Kafka.main(Kafka.scala)
[2021-04-14 20:13:49,144] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:13:49,146] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-04-14 20:13:49,153] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-04-14 20:13:49,157] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-04-14 20:13:49,159] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:13:49,160] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:13:49,160] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:13:49,161] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:13:49,163] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:13:49,165] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 20:13:49,168] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 20:13:49,169] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:49,182] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:49,182] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:49,183] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:49,389] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:49,389] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:49,390] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:49,590] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:49,590] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:49,594] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:49,795] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:49,795] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:13:49,807] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-04-14 20:13:49,808] INFO Shutting down. (kafka.log.LogManager)
[2021-04-14 20:13:49,912] INFO Shutdown complete. (kafka.log.LogManager)
[2021-04-14 20:13:49,914] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:13:50,045] INFO Session: 0x100052a53dd0000 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:13:50,045] INFO EventThread shut down for session: 0x100052a53dd0000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:13:50,048] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:13:50,049] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:50,878] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:50,878] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:50,879] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:50,894] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:50,894] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:50,895] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:51,897] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:51,897] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:13:51,901] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-04-14 20:13:51,935] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2021-04-14 20:13:51,940] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-14 20:13:51,941] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2021-04-14 20:13:51,943] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:14:01,798] INFO Expiring session 0x100052602770001, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:01,799] INFO Expiring session 0x10005294c4d0000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:27,907] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:14:27,919] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:14:27,919] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:14:27,923] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:14:27,923] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:14:27,923] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:14:27,923] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:14:27,925] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:14:27,954] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:14:27,955] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:14:27,955] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:14:27,955] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:14:27,962] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:14:27,997] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 20:14:28,449] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 20:14:28,518] INFO starting (kafka.server.KafkaServer)
[2021-04-14 20:14:28,519] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 20:14:28,548] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:14:32,516] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,516] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,516] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,516] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,517] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,517] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,518] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,518] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,518] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,519] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,519] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,519] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,519] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,519] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,519] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,519] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,519] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,519] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,521] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,521] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,522] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:32,537] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:14:32,540] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:14:32,548] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:14:32,569] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 20:14:32,575] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.ee (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 20:14:32,603] INFO Snapshotting: 0x100 to D:\temp\zookeeper\version-2\snapshot.100 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:14:32,629] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 20:14:33,081] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,081] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,081] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,081] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,081] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,082] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,082] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,083] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,083] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,083] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,083] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,083] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,083] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,083] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,083] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,083] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,084] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,084] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,087] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:33,100] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 20:14:33,107] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:14:33,110] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:14:33,114] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:14:33,116] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:63241, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:14:33,124] INFO Creating new log file: log.101 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 20:14:33,156] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100052b16350000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:14:33,161] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:14:33,595] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 20:14:33,689] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:14:33,697] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:14:33,729] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:14:33,729] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:14:33,731] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:14:33,773] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 20:14:33,918] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 139 with message format version 2 (kafka.log.Log)
[2021-04-14 20:14:33,936] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000139.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 20:14:33,944] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 139 in 138 ms (kafka.log.Log)
[2021-04-14 20:14:33,957] INFO Logs loading complete in 183 ms. (kafka.log.LogManager)
[2021-04-14 20:14:33,972] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 20:14:33,974] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 20:14:34,461] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 20:14:34,517] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 20:14:34,519] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 20:14:34,543] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:14:34,543] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:14:34,544] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:14:34,545] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:14:34,562] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:14:38,403] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:14:38,411] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:14:38,412] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:14:38,415] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:14:38,416] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:14:38,416] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:14:38,417] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:14:38,419] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:14:38,441] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:14:38,442] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:14:38,443] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:14:38,443] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:14:38,448] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:14:38,485] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 20:14:38,811] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 20:14:38,861] INFO starting (kafka.server.KafkaServer)
[2021-04-14 20:14:38,863] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 20:14:38,883] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:14:39,140] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 20:14:39,186] INFO Stat of the created znode at /brokers/ids/0 is: 271,271,1618442079155,1618442079155,1,0,0,72063276652232704,200,0,271
 (kafka.zk.KafkaZkClient)
[2021-04-14 20:14:39,187] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArraySeq(EndPoint(DESKTOP-N4251U6,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 271 (kafka.zk.KafkaZkClient)
[2021-04-14 20:14:39,279] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:14:39,283] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:14:39,284] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:14:39,335] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 20:14:39,336] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 20:14:39,347] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2021-04-14 20:14:39,364] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:6000,blockEndProducerId:6999) by writing to Zk with path version 7 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-14 20:14:39,392] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 20:14:39,394] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-14 20:14:39,394] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 20:14:39,423] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:14:39,448] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-14 20:14:39,503] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2021-04-14 20:14:39,510] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:14:39,510] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:14:39,510] INFO Kafka startTimeMs: 1618442079504 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:14:39,513] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-04-14 20:14:39,586] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(twitter-0) (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:14:39,599] INFO [Partition twitter-0 broker=0] Log loaded for partition twitter-0 with initial high watermark 139 (kafka.cluster.Partition)
[2021-04-14 20:14:39,601] INFO [Partition twitter-0 broker=0] twitter-0 starts at leader epoch 0 from offset 139 with high watermark 139. Previous leader epoch was -1. (kafka.cluster.Partition)
[2021-04-14 20:14:42,995] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:42,996] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:42,997] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:42,998] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:42,998] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:42,999] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:43,012] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:43,014] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:43,014] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:43,014] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:43,015] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:43,015] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:43,015] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:43,016] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:43,016] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:43,017] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:43,017] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:43,017] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:43,019] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:43,020] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:43,021] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:14:43,035] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:14:43,039] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:14:43,048] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:14:43,049] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Unknown Source)
	at sun.nio.ch.Net.bind(Unknown Source)
	at sun.nio.ch.ServerSocketChannelImpl.bind(Unknown Source)
	at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:687)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:143)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:106)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:64)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:128)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:82)
[2021-04-14 20:14:43,414] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,416] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,417] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,418] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,418] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,419] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,437] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,439] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,439] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,440] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,440] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,440] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,441] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,441] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,441] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,442] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,442] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,442] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,445] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:43,456] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 20:14:43,464] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:14:43,467] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:14:43,471] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:14:43,474] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:63275, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:14:43,505] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100052b16350001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:14:43,518] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:14:43,886] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 20:14:43,977] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:14:44,002] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:14:44,046] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:14:44,047] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:14:44,048] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:14:44,084] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in D:\temp\kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:238)
	at scala.collection.StrictOptimizedIterableOps.flatMap(StrictOptimizedIterableOps.scala:118)
	at scala.collection.StrictOptimizedIterableOps.flatMap$(StrictOptimizedIterableOps.scala:105)
	at scala.collection.mutable.ArraySeq.flatMap(ArraySeq.scala:38)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:233)
	at kafka.log.LogManager.<init>(LogManager.scala:104)
	at kafka.log.LogManager$.apply(LogManager.scala:1084)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:253)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:82)
	at kafka.Kafka.main(Kafka.scala)
[2021-04-14 20:14:44,088] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:14:44,093] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:14:44,225] INFO Session: 0x100052b16350001 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:14:44,225] INFO EventThread shut down for session: 0x100052b16350001 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:14:44,229] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:14:44,231] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:14:45,057] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:14:45,057] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:14:45,057] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:14:46,070] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:14:46,070] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:14:46,070] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:14:47,072] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:14:47,072] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:14:47,086] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-14 20:14:47,087] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2021-04-14 20:14:47,089] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:14:58,387] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:14:58,389] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2021-04-14 20:14:58,716] WARN Session 0x100052b16350000 for server localhost/0:0:0:0:0:0:0:1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Se ha forzado la interrupción de una conexión existente por el host remoto
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(Unknown Source)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(Unknown Source)
	at sun.nio.ch.IOUtil.read(Unknown Source)
	at sun.nio.ch.SocketChannelImpl.read(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:75)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1223)
[2021-04-14 20:14:58,820] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:14:58,820] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:15:00,548] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:02,577] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:02,686] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:15:04,370] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:06,398] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:07,726] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:09,763] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:11,458] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:13,505] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:14,931] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:16,958] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:18,100] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:20,134] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:21,528] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:23,545] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:24,947] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:26,966] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:28,862] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:30,911] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:32,644] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:34,676] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:36,561] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:38,589] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:40,197] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:42,225] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:44,284] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:46,315] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:48,008] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:50,022] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:51,960] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:53,985] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:55,220] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:57,244] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:15:58,862] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:00,893] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:02,274] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:04,304] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:05,786] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:07,814] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:09,927] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:11,945] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:13,824] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:15,850] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:17,514] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:19,551] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:21,212] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:23,241] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:24,383] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:25,599] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:16:25,607] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:16:25,607] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:16:25,610] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:16:25,610] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:16:25,610] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:16:25,610] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:16:25,612] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:16:25,630] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:16:25,631] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:16:25,631] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:16:25,631] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:16:25,633] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 20:16:25,634] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:16:25,969] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 20:16:26,017] INFO starting (kafka.server.KafkaServer)
[2021-04-14 20:16:26,019] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 20:16:26,038] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:16:26,424] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:28,513] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:30,178] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,179] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,179] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,180] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,180] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,181] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,192] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,193] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,194] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,194] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,195] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,196] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,196] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,197] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,197] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,198] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,198] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,199] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,201] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,201] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,202] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:16:30,221] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:16:30,225] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:16:30,234] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:16:30,255] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 20:16:30,269] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.100 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 20:16:30,300] INFO Snapshotting: 0x121 to D:\temp\zookeeper\version-2\snapshot.121 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:16:30,322] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 20:16:30,523] INFO Socket connection established, initiating session, client: /127.0.0.1:63415, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:30,541] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100052b16350000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:30,541] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:16:30,567] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2021-04-14 20:16:30,570] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-14 20:16:30,571] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-14 20:16:30,571] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-14 20:16:30,571] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-04-14 20:16:30,581] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-04-14 20:16:30,582] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2021-04-14 20:16:30,584] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2021-04-14 20:16:30,586] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,587] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,588] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:30,588] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,588] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,588] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,589] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,599] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,601] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,603] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,603] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,603] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,604] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,604] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,604] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,605] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,605] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,606] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,606] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,609] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:30,621] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 20:16:30,627] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:30,630] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:16:30,636] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:30,638] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:63427, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:30,642] INFO Creating new log file: log.122 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 20:16:30,658] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100052ce1f50000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:30,671] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:16:30,742] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:30,742] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:30,743] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2021-04-14 20:16:30,744] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:30,821] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:30,821] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:30,823] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 20:16:30,824] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 6000 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-14 20:16:30,825] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2021-04-14 20:16:30,825] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-14 20:16:30,826] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-14 20:16:30,826] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-14 20:16:30,827] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 20:16:30,829] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 20:16:30,830] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,027] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,027] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,027] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,043] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 20:16:31,127] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:16:31,187] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:16:31,243] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,243] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,244] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 20:16:31,245] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-04-14 20:16:31,245] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:16:31,245] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:16:31,245] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:16:31,246] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:16:31,249] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:16:31,250] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 20:16:31,250] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 20:16:31,250] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,268] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:31,269] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:31,271] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:31,308] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in D:\temp\kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:238)
	at scala.collection.StrictOptimizedIterableOps.flatMap(StrictOptimizedIterableOps.scala:118)
	at scala.collection.StrictOptimizedIterableOps.flatMap$(StrictOptimizedIterableOps.scala:105)
	at scala.collection.mutable.ArraySeq.flatMap(ArraySeq.scala:38)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:233)
	at kafka.log.LogManager.<init>(LogManager.scala:104)
	at kafka.log.LogManager$.apply(LogManager.scala:1084)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:253)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:82)
	at kafka.Kafka.main(Kafka.scala)
[2021-04-14 20:16:31,315] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:16:31,319] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:16:31,322] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,322] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,322] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,414] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,414] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,414] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,430] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,430] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,431] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,432] INFO Session: 0x100052ce1f50000 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:31,432] INFO EventThread shut down for session: 0x100052ce1f50000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:31,436] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:16:31,438] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:31,617] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,617] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:16:31,646] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-04-14 20:16:31,647] INFO Shutting down. (kafka.log.LogManager)
[2021-04-14 20:16:31,677] INFO [ProducerStateManager partition=twitter-0] Writing producer snapshot at offset 144 (kafka.log.ProducerStateManager)
[2021-04-14 20:16:31,759] INFO Shutdown complete. (kafka.log.LogManager)
[2021-04-14 20:16:31,767] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:16:31,886] INFO Session: 0x100052b16350000 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:16:31,886] INFO EventThread shut down for session: 0x100052b16350000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:16:31,888] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:16:31,889] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:32,272] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:32,272] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:32,273] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:32,524] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:32,524] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:32,524] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:33,280] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:33,280] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:33,281] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:33,531] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:33,531] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:33,531] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:33,547] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:33,547] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:33,548] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-04-14 20:16:33,576] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2021-04-14 20:16:33,579] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-14 20:16:34,282] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:34,282] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:16:34,291] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-14 20:16:34,292] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2021-04-14 20:16:34,293] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:17:49,503] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:17:49,511] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:17:49,511] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:17:49,514] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:17:49,514] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:17:49,514] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:17:49,514] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:17:49,516] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:17:49,535] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:17:49,535] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:17:49,535] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:17:49,536] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:17:49,540] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:17:49,621] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 20:17:49,957] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 20:17:50,009] INFO starting (kafka.server.KafkaServer)
[2021-04-14 20:17:50,010] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 20:17:50,030] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:17:54,084] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,085] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,085] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,086] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,087] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,087] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,098] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,100] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,101] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,101] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,101] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,102] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,102] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,103] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,103] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,103] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,104] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,104] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,106] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,107] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,108] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:17:54,126] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:17:54,130] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:17:54,139] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:17:54,161] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 20:17:54,177] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.121 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 20:17:54,221] INFO Snapshotting: 0x131 to D:\temp\zookeeper\version-2\snapshot.131 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:17:54,251] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 20:17:54,551] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,552] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,552] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,552] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,553] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,553] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,563] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,565] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,566] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,566] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,567] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,567] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,567] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,568] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,568] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,569] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,569] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,569] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,572] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:17:54,585] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 20:17:54,594] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:17:54,597] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:17:54,602] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:17:54,605] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:63540, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:17:54,613] INFO Creating new log file: log.132 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 20:17:54,649] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100052e29ca0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:17:54,662] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:17:55,073] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 20:17:55,158] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:17:55,268] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:17:55,385] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:17:55,385] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:17:55,387] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:17:55,441] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 20:17:55,651] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 144 with message format version 2 (kafka.log.Log)
[2021-04-14 20:17:55,670] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000144.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 20:17:55,678] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 144 in 191 ms (kafka.log.Log)
[2021-04-14 20:17:55,693] INFO Logs loading complete in 252 ms. (kafka.log.LogManager)
[2021-04-14 20:17:55,708] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 20:17:55,710] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 20:17:56,355] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 20:17:56,418] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 20:17:56,419] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 20:17:56,444] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:17:56,447] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:17:56,448] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:17:56,453] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:17:56,487] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:18:01,095] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 20:18:01,142] INFO Stat of the created znode at /brokers/ids/0 is: 320,320,1618442281111,1618442281111,1,0,0,72063289865666560,200,0,320
 (kafka.zk.KafkaZkClient)
[2021-04-14 20:18:01,144] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArraySeq(EndPoint(DESKTOP-N4251U6,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 320 (kafka.zk.KafkaZkClient)
[2021-04-14 20:18:01,231] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:18:01,235] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:18:01,237] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:18:01,274] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 20:18:01,276] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 20:18:01,283] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2021-04-14 20:18:01,304] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:7000,blockEndProducerId:7999) by writing to Zk with path version 8 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-14 20:18:01,331] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 20:18:01,334] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-14 20:18:01,334] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 20:18:01,368] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:18:01,391] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-14 20:18:01,436] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2021-04-14 20:18:01,452] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:18:01,454] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:18:01,456] INFO Kafka startTimeMs: 1618442281438 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:18:01,460] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-04-14 20:18:01,537] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(twitter-0) (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:18:01,549] INFO [Partition twitter-0 broker=0] Log loaded for partition twitter-0 with initial high watermark 144 (kafka.cluster.Partition)
[2021-04-14 20:18:01,551] INFO [Partition twitter-0 broker=0] twitter-0 starts at leader epoch 0 from offset 144 with high watermark 144. Previous leader epoch was -1. (kafka.cluster.Partition)
[2021-04-14 20:18:31,649] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:18:31,652] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2021-04-14 20:18:31,975] WARN Session 0x100052e29ca0000 for server localhost/0:0:0:0:0:0:0:1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Se ha forzado la interrupción de una conexión existente por el host remoto
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(Unknown Source)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(Unknown Source)
	at sun.nio.ch.IOUtil.read(Unknown Source)
	at sun.nio.ch.SocketChannelImpl.read(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:75)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1223)
[2021-04-14 20:18:32,085] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:18:32,085] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:18:33,353] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:18:35,381] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:18:35,491] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:18:37,056] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:18:39,089] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:18:40,882] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:18:42,931] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:18:44,058] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:18:46,098] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:18:47,650] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:18:49,673] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:18:51,612] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:18:53,628] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:20:31,958] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 20:20:31,985] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:20:31,994] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:20:31,994] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:20:31,997] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:20:31,997] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:20:31,997] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:20:31,998] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:20:31,999] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:20:32,016] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:20:32,017] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:20:32,017] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:20:32,018] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:20:32,021] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:20:32,312] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 20:20:32,362] INFO starting (kafka.server.KafkaServer)
[2021-04-14 20:20:32,364] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 20:20:32,385] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:20:36,557] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,559] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,560] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,561] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,562] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,563] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,581] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,583] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,584] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,584] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,585] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,585] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,585] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,586] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,586] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,587] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,588] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,588] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,591] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,591] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,592] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:20:36,610] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:20:36,613] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:20:36,622] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:20:36,641] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 20:20:36,653] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.131 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 20:20:36,687] INFO Snapshotting: 0x143 to D:\temp\zookeeper\version-2\snapshot.143 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:20:36,708] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 20:20:36,916] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,917] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,918] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,919] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,920] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,921] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,939] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,941] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,941] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,942] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,942] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,942] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,943] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,943] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,943] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,944] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,944] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,944] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,948] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:36,959] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 20:20:36,967] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:20:36,969] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:20:36,973] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:20:36,976] INFO Socket connection established, initiating session, client: /127.0.0.1:63773, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:20:36,985] INFO Creating new log file: log.144 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 20:20:37,011] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000530a4670000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:20:37,023] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:20:37,412] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 20:20:37,491] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:20:37,551] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:20:37,632] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:20:37,633] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:20:37,634] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:20:37,672] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 20:20:37,729] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2021-04-14 20:20:37,731] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-14 20:20:37,784] INFO [ProducerStateManager partition=twitter-0] Writing producer snapshot at offset 144 (kafka.log.ProducerStateManager)
[2021-04-14 20:20:37,842] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 144 with message format version 2 (kafka.log.Log)
[2021-04-14 20:20:37,844] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000144.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 20:20:37,848] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 144 in 147 ms (kafka.log.Log)
[2021-04-14 20:20:37,858] INFO Logs loading complete in 186 ms. (kafka.log.LogManager)
[2021-04-14 20:20:37,870] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 20:20:37,871] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 20:20:38,217] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 20:20:38,260] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 20:20:38,262] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 20:20:38,280] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:20:38,281] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:20:38,281] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:20:38,282] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:20:38,294] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:20:42,900] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 20:20:42,950] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72063289865666560' does not match current session '72063300512710656' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2021-04-14 20:20:42,961] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1819)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1757)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1724)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:95)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:273)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:82)
	at kafka.Kafka.main(Kafka.scala)
[2021-04-14 20:20:42,970] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:20:42,972] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-04-14 20:20:42,978] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-04-14 20:20:42,982] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-04-14 20:20:42,983] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:20:42,984] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:20:42,984] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:20:42,986] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:20:42,988] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:20:42,989] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 20:20:42,990] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 20:20:42,991] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:20:43,174] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:20:43,174] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:20:43,175] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:20:43,378] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:20:43,378] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:20:43,380] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:20:43,582] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:20:43,582] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:20:43,585] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:20:43,788] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:20:43,788] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:20:43,795] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-04-14 20:20:43,796] INFO Shutting down. (kafka.log.LogManager)
[2021-04-14 20:20:43,993] INFO Shutdown complete. (kafka.log.LogManager)
[2021-04-14 20:20:43,994] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:20:44,116] INFO Session: 0x1000530a4670000 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:20:44,116] INFO EventThread shut down for session: 0x1000530a4670000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:20:44,120] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:20:44,121] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:20:44,709] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:20:44,709] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:20:44,712] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:20:45,711] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:20:45,711] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:20:45,712] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:20:46,727] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:20:46,727] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:20:46,729] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-04-14 20:20:46,776] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2021-04-14 20:20:46,783] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-14 20:20:46,784] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2021-04-14 20:20:46,785] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:20:55,798] INFO Expiring session 0x100052e29ca0000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:44,966] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:21:44,974] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:21:44,974] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:21:44,977] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:21:44,977] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:21:44,978] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:21:44,978] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:21:44,979] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:21:44,986] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 20:21:44,996] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:21:44,997] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:21:44,997] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:21:44,997] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:21:45,002] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:21:45,321] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 20:21:45,371] INFO starting (kafka.server.KafkaServer)
[2021-04-14 20:21:45,372] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 20:21:45,393] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:21:49,556] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,558] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,560] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,560] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,561] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,563] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,577] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,579] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,580] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,580] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,580] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,581] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,581] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,581] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,582] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,582] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,582] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,583] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,585] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,585] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,586] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:21:49,600] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:21:49,603] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:21:49,612] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:21:49,629] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 20:21:49,641] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.143 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 20:21:49,669] INFO Snapshotting: 0x154 to D:\temp\zookeeper\version-2\snapshot.154 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:21:49,689] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 20:21:49,934] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,935] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,935] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,936] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,936] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,937] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,951] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,953] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,954] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,954] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,955] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,955] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,956] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,957] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,957] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,957] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,958] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,958] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,962] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:21:49,974] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 20:21:49,981] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:21:49,983] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:21:49,988] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:21:49,990] INFO Socket connection established, initiating session, client: /127.0.0.1:63870, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:21:49,998] INFO Creating new log file: log.155 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 20:21:50,035] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000531c17e0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:21:50,047] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:21:50,432] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 20:21:50,513] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:21:50,568] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:21:50,643] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:21:50,643] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:21:50,645] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:21:50,682] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 20:21:50,811] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 144 with message format version 2 (kafka.log.Log)
[2021-04-14 20:21:50,828] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000144.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 20:21:50,836] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 144 in 122 ms (kafka.log.Log)
[2021-04-14 20:21:50,849] INFO Logs loading complete in 167 ms. (kafka.log.LogManager)
[2021-04-14 20:21:50,863] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 20:21:50,865] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 20:21:51,259] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 20:21:51,304] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 20:21:51,305] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 20:21:51,327] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:21:51,328] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:21:51,328] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:21:51,330] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:21:51,346] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:21:55,922] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 20:21:55,972] INFO Stat of the created znode at /brokers/ids/0 is: 355,355,1618442515938,1618442515938,1,0,0,72063305295724544,200,0,355
 (kafka.zk.KafkaZkClient)
[2021-04-14 20:21:55,974] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArraySeq(EndPoint(DESKTOP-N4251U6,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 355 (kafka.zk.KafkaZkClient)
[2021-04-14 20:21:56,067] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:21:56,071] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:21:56,073] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:21:56,109] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 20:21:56,111] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 20:21:56,117] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2021-04-14 20:21:56,133] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:8000,blockEndProducerId:8999) by writing to Zk with path version 9 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-14 20:21:56,159] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 20:21:56,161] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-14 20:21:56,161] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 20:21:56,194] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:21:56,218] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-14 20:21:56,274] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2021-04-14 20:21:56,282] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:21:56,288] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:21:56,289] INFO Kafka startTimeMs: 1618442516277 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:21:56,292] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-04-14 20:21:56,346] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(twitter-0) (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:21:56,357] INFO [Partition twitter-0 broker=0] Log loaded for partition twitter-0 with initial high watermark 144 (kafka.cluster.Partition)
[2021-04-14 20:21:56,359] INFO [Partition twitter-0 broker=0] twitter-0 starts at leader epoch 0 from offset 144 with high watermark 144. Previous leader epoch was -1. (kafka.cluster.Partition)
[2021-04-14 20:22:21,028] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:22:21,031] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2021-04-14 20:22:21,356] WARN Session 0x1000531c17e0000 for server localhost/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Se ha forzado la interrupción de una conexión existente por el host remoto
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(Unknown Source)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(Unknown Source)
	at sun.nio.ch.IOUtil.read(Unknown Source)
	at sun.nio.ch.SocketChannelImpl.read(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:75)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1223)
[2021-04-14 20:22:21,474] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:22:21,474] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:22:23,146] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:25,160] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:25,269] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:22:26,406] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:28,426] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:29,594] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:31,633] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:33,654] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:35,691] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:37,634] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:39,678] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:41,606] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:43,645] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:44,854] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:46,879] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:48,642] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:50,666] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:52,738] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:54,768] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:56,614] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:58,641] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:22:59,802] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:01,827] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:03,112] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:05,158] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:07,042] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:09,070] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:10,483] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:12,499] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:13,938] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:15,958] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:18,028] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:20,048] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:21,287] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:23,313] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:25,104] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:27,141] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:29,139] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:31,193] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:32,459] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:34,478] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:35,673] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:37,706] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:39,569] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:41,612] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:43,235] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:45,272] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:47,098] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:49,145] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:50,424] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:52,438] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:53,554] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:55,613] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:57,710] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:23:59,737] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:24:01,595] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:24:03,604] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:24:05,097] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:24:07,127] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:24:09,121] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:24:49,847] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:24:49,855] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:24:49,856] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:24:49,858] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:24:49,858] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:24:49,858] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:24:49,859] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:24:49,860] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:24:49,879] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:24:49,879] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:24:49,880] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:24:49,880] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:24:49,883] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:24:49,889] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 20:24:50,241] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 20:24:50,293] INFO starting (kafka.server.KafkaServer)
[2021-04-14 20:24:50,294] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 20:24:50,315] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:24:54,422] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,423] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,424] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,425] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,426] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,426] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,439] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,441] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,442] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,442] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,443] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,443] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,443] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,444] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,444] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,445] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,445] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,446] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,448] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,449] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,450] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:24:54,471] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:24:54,474] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:24:54,486] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:24:54,512] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 20:24:54,527] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.154 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 20:24:54,565] INFO Snapshotting: 0x166 to D:\temp\zookeeper\version-2\snapshot.166 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:24:54,589] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 20:24:54,850] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,851] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,851] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,852] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,852] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,853] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,865] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,867] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,868] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,868] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,869] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,869] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,870] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,870] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,870] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,871] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,871] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,871] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,875] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:24:54,887] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 20:24:54,897] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:24:54,900] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:24:54,905] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:24:54,908] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:64130, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:24:54,918] INFO Creating new log file: log.167 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 20:24:54,957] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100053493be0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:24:54,969] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:24:55,344] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 20:24:55,422] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:24:55,470] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:24:55,538] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:24:55,539] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:24:55,540] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:24:55,575] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 20:24:55,631] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2021-04-14 20:24:55,633] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-14 20:24:55,689] INFO [ProducerStateManager partition=twitter-0] Writing producer snapshot at offset 146 (kafka.log.ProducerStateManager)
[2021-04-14 20:24:55,739] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 146 with message format version 2 (kafka.log.Log)
[2021-04-14 20:24:55,741] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000146.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 20:24:55,745] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 146 in 144 ms (kafka.log.Log)
[2021-04-14 20:24:55,756] INFO Logs loading complete in 181 ms. (kafka.log.LogManager)
[2021-04-14 20:24:55,769] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 20:24:55,770] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 20:24:56,101] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 20:24:56,139] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 20:24:56,141] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 20:24:56,157] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:24:56,158] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:24:56,159] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:24:56,158] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:24:56,171] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:25:00,762] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 20:25:00,797] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72063305295724544' does not match current session '72063317413068800' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2021-04-14 20:25:00,807] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1819)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1757)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1724)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:95)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:273)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:82)
	at kafka.Kafka.main(Kafka.scala)
[2021-04-14 20:25:00,812] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:25:00,814] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-04-14 20:25:00,821] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-04-14 20:25:00,825] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-04-14 20:25:00,827] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:25:00,828] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:25:00,828] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:25:00,829] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:25:00,831] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:25:00,833] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 20:25:00,834] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 20:25:00,835] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:25:00,850] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:25:00,850] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:25:00,852] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:25:01,056] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:25:01,056] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:25:01,059] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:25:01,261] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:25:01,261] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:25:01,263] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:25:01,467] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:25:01,467] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:25:01,475] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-04-14 20:25:01,476] INFO Shutting down. (kafka.log.LogManager)
[2021-04-14 20:25:01,580] INFO Shutdown complete. (kafka.log.LogManager)
[2021-04-14 20:25:01,581] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:25:01,708] INFO Session: 0x100053493be0000 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:25:01,708] INFO EventThread shut down for session: 0x100053493be0000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:25:01,711] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:25:01,712] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:25:02,616] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:25:02,616] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:25:02,617] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:25:03,622] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:25:03,622] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:25:03,624] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:25:04,626] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:25:04,626] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:25:04,630] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-04-14 20:25:04,667] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2021-04-14 20:25:04,673] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-14 20:25:04,674] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2021-04-14 20:25:04,675] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:25:13,808] INFO Expiring session 0x1000531c17e0000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:37,453] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:28:37,461] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:28:37,462] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:28:37,465] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:28:37,465] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:28:37,465] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 20:28:37,465] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 20:28:37,467] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 20:28:37,484] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:28:37,485] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:28:37,485] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 20:28:37,486] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 20:28:37,489] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 20:28:37,592] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 20:28:37,925] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 20:28:37,975] INFO starting (kafka.server.KafkaServer)
[2021-04-14 20:28:37,976] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 20:28:37,997] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:28:42,035] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,037] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,038] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,039] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,040] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,041] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,057] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,059] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,059] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,060] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,060] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,060] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,061] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,061] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,061] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,062] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,062] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,063] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,065] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,065] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,066] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 20:28:42,081] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 20:28:42,085] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:28:42,093] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 20:28:42,095] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Unknown Source)
	at sun.nio.ch.Net.bind(Unknown Source)
	at sun.nio.ch.ServerSocketChannelImpl.bind(Unknown Source)
	at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:687)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:143)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:106)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:64)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:128)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:82)
[2021-04-14 20:28:42,524] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,526] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,527] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,528] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,529] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,530] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,548] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,551] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,552] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,552] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,553] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,553] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,553] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,554] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,554] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,554] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,555] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,556] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,559] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 20:28:42,570] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 20:28:42,578] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:28:42,581] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:28:42,586] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:28:42,590] INFO Socket connection established, initiating session, client: /127.0.0.1:64395, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:28:42,626] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100053493be0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:28:42,642] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:28:43,012] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 20:28:43,090] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:28:43,149] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 20:28:43,231] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:28:43,231] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:28:43,233] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 20:28:43,271] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 20:28:43,416] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 146 with message format version 2 (kafka.log.Log)
[2021-04-14 20:28:43,437] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000146.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 20:28:43,443] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 146 in 139 ms (kafka.log.Log)
[2021-04-14 20:28:43,456] INFO Logs loading complete in 185 ms. (kafka.log.LogManager)
[2021-04-14 20:28:43,471] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 20:28:43,472] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 20:28:43,871] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 20:28:43,917] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 20:28:43,919] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 20:28:43,943] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:28:43,944] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:28:43,944] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:28:43,946] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:28:43,962] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 20:28:48,557] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 20:28:48,602] INFO Stat of the created znode at /brokers/ids/0 is: 390,390,1618442928570,1618442928570,1,0,0,72063317413068801,200,0,390
 (kafka.zk.KafkaZkClient)
[2021-04-14 20:28:48,604] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArraySeq(EndPoint(DESKTOP-N4251U6,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 390 (kafka.zk.KafkaZkClient)
[2021-04-14 20:28:48,702] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:28:48,706] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:28:48,707] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:28:48,736] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 20:28:48,739] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 20:28:48,747] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2021-04-14 20:28:48,767] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:9000,blockEndProducerId:9999) by writing to Zk with path version 10 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-14 20:28:48,793] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 20:28:48,796] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-14 20:28:48,797] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 20:28:48,833] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 20:28:48,859] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-14 20:28:48,887] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2021-04-14 20:28:48,896] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:28:48,898] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:28:48,899] INFO Kafka startTimeMs: 1618442928890 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 20:28:48,914] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-04-14 20:28:49,028] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(twitter-0) (kafka.server.ReplicaFetcherManager)
[2021-04-14 20:28:49,043] INFO [Partition twitter-0 broker=0] Log loaded for partition twitter-0 with initial high watermark 146 (kafka.cluster.Partition)
[2021-04-14 20:28:49,046] INFO [Partition twitter-0 broker=0] twitter-0 starts at leader epoch 0 from offset 146 with high watermark 146. Previous leader epoch was -1. (kafka.cluster.Partition)
[2021-04-14 20:28:51,050] WARN Session 0x100053493be0001 for server localhost/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Se ha forzado la interrupción de una conexión existente por el host remoto
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(Unknown Source)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(Unknown Source)
	at sun.nio.ch.IOUtil.read(Unknown Source)
	at sun.nio.ch.SocketChannelImpl.read(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:75)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1223)
[2021-04-14 20:28:52,916] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:28:54,940] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:28:56,352] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:28:58,385] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:28:59,878] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:29:01,915] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:29:02,579] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 20:29:02,582] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2021-04-14 20:29:03,565] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:29:05,589] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:29:05,702] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 20:29:06,883] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:29:08,906] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:29:10,256] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 20:29:12,276] INFO Socket error occurred: localhost/0:0:0:0:0:0:0:1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 21:06:30,074] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 21:06:30,082] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 21:06:30,083] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 21:06:30,086] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 21:06:30,086] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 21:06:30,086] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 21:06:30,086] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 21:06:30,088] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 21:06:30,106] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 21:06:30,105] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 21:06:30,106] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 21:06:30,106] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 21:06:30,107] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 21:06:30,110] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 21:06:30,440] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 21:06:30,492] INFO starting (kafka.server.KafkaServer)
[2021-04-14 21:06:30,494] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 21:06:30,513] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 21:06:34,651] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,653] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,654] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,655] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,656] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,658] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,675] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,676] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,677] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,677] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,678] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,678] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,679] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,679] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,679] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,680] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,680] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,681] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,684] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,685] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,686] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:06:34,699] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 21:06:34,703] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 21:06:34,711] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 21:06:34,728] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 21:06:34,741] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.166 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 21:06:34,770] INFO Snapshotting: 0x189 to D:\temp\zookeeper\version-2\snapshot.189 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 21:06:34,790] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 21:06:35,026] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,028] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,028] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,029] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,030] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,031] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,049] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,051] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,052] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,052] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,052] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,053] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,053] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,053] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,054] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,054] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,054] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,055] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,057] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:35,067] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 21:06:35,074] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 21:06:35,076] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 21:06:35,080] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 21:06:35,084] INFO Socket connection established, initiating session, client: /127.0.0.1:50616, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 21:06:35,091] INFO Creating new log file: log.18a (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 21:06:35,128] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100055aba2b0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 21:06:35,139] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 21:06:35,515] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 21:06:35,599] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 21:06:35,654] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 21:06:35,725] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 21:06:35,726] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 21:06:35,728] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 21:06:35,766] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 21:06:35,826] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2021-04-14 21:06:35,828] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2021-04-14 21:06:35,887] INFO [ProducerStateManager partition=twitter-0] Writing producer snapshot at offset 146 (kafka.log.ProducerStateManager)
[2021-04-14 21:06:35,945] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 146 with message format version 2 (kafka.log.Log)
[2021-04-14 21:06:35,948] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000146.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 21:06:35,953] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 146 in 159 ms (kafka.log.Log)
[2021-04-14 21:06:35,966] INFO Logs loading complete in 199 ms. (kafka.log.LogManager)
[2021-04-14 21:06:35,976] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 21:06:35,977] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 21:06:36,308] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 21:06:36,350] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 21:06:36,351] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 21:06:36,370] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:06:36,371] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:06:36,371] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:06:36,372] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:06:36,384] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 21:06:40,979] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 21:06:41,027] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72063317413068801' does not match current session '72063481266503680' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2021-04-14 21:06:41,037] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1819)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1757)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1724)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:95)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:273)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:82)
	at kafka.Kafka.main(Kafka.scala)
[2021-04-14 21:06:41,044] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 21:06:41,045] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2021-04-14 21:06:41,051] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2021-04-14 21:06:41,055] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2021-04-14 21:06:41,057] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 21:06:41,058] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 21:06:41,058] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 21:06:41,059] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2021-04-14 21:06:41,061] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2021-04-14 21:06:41,063] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 21:06:41,064] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2021-04-14 21:06:41,065] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:06:41,257] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:06:41,257] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:06:41,258] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:06:41,457] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:06:41,457] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:06:41,459] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:06:41,662] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:06:41,662] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:06:41,663] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:06:41,863] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:06:41,863] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:06:41,870] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2021-04-14 21:06:41,871] INFO Shutting down. (kafka.log.LogManager)
[2021-04-14 21:06:41,977] INFO Shutdown complete. (kafka.log.LogManager)
[2021-04-14 21:06:41,979] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 21:06:42,102] INFO Session: 0x100055aba2b0000 closed (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:06:42,102] INFO EventThread shut down for session: 0x100055aba2b0000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 21:06:42,105] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 21:06:42,107] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 21:06:42,801] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 21:06:42,801] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 21:06:42,803] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 21:06:43,816] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 21:06:43,816] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 21:06:43,817] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 21:06:44,825] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 21:06:44,825] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 21:06:44,826] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2021-04-14 21:06:44,859] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2021-04-14 21:06:44,866] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2021-04-14 21:06:44,867] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2021-04-14 21:06:44,868] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 21:06:52,797] INFO Expiring session 0x100053493be0001, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:12,585] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 21:08:12,591] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 21:08:12,591] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 21:08:12,593] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 21:08:12,593] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 21:08:12,594] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2021-04-14 21:08:12,594] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2021-04-14 21:08:12,595] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2021-04-14 21:08:12,611] INFO Reading configuration from: ./kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 21:08:12,612] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 21:08:12,612] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2021-04-14 21:08:12,612] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2021-04-14 21:08:12,616] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 21:08:17,163] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,165] INFO Server environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,166] INFO Server environment:java.version=1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,167] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,167] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,168] INFO Server environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,179] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,182] INFO Server environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,183] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,183] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,183] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,184] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,184] INFO Server environment:user.name=Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,184] INFO Server environment:user.home=C:\Users\Gab (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,185] INFO Server environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,185] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,186] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,186] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,188] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,189] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,189] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir D:\temp\zookeeper\version-2 snapdir D:\temp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2021-04-14 21:08:17,206] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2021-04-14 21:08:17,210] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 21:08:17,218] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2021-04-14 21:08:17,236] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2021-04-14 21:08:17,249] INFO Reading snapshot D:\temp\zookeeper\version-2\snapshot.189 (org.apache.zookeeper.server.persistence.FileSnap)
[2021-04-14 21:08:17,277] INFO Snapshotting: 0x19a to D:\temp\zookeeper\version-2\snapshot.19a (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2021-04-14 21:08:17,298] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2021-04-14 21:08:43,173] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2021-04-14 21:08:43,504] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2021-04-14 21:08:43,555] INFO starting (kafka.server.KafkaServer)
[2021-04-14 21:08:43,556] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2021-04-14 21:08:43,577] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 21:08:48,122] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,123] INFO Client environment:host.name=DESKTOP-N4251U6 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,123] INFO Client environment:java.version=1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,123] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,124] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_281 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,125] INFO Client environment:java.class.path=D:\streaming_bigdata\kafka\libs\activation-1.1.1.jar;D:\streaming_bigdata\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\streaming_bigdata\kafka\libs\argparse4j-0.7.0.jar;D:\streaming_bigdata\kafka\libs\audience-annotations-0.5.0.jar;D:\streaming_bigdata\kafka\libs\commons-cli-1.4.jar;D:\streaming_bigdata\kafka\libs\commons-lang3-3.8.1.jar;D:\streaming_bigdata\kafka\libs\connect-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-file-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-json-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-mirror-client-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-runtime-2.5.0.jar;D:\streaming_bigdata\kafka\libs\connect-transforms-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-api-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-locator-2.5.0.jar;D:\streaming_bigdata\kafka\libs\hk2-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jackson-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-core-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-databind-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jackson-module-scala_2.13-2.10.2.jar;D:\streaming_bigdata\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\streaming_bigdata\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\streaming_bigdata\kafka\libs\jakarta.inject-2.5.0.jar;D:\streaming_bigdata\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\streaming_bigdata\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.22.0-CR2.jar;D:\streaming_bigdata\kafka\libs\javassist-3.26.0-GA.jar;D:\streaming_bigdata\kafka\libs\javax.servlet-api-3.1.0.jar;D:\streaming_bigdata\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\streaming_bigdata\kafka\libs\jaxb-api-2.3.0.jar;D:\streaming_bigdata\kafka\libs\jersey-client-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-common-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-hk2-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-media-jaxb-2.28.jar;D:\streaming_bigdata\kafka\libs\jersey-server-2.28.jar;D:\streaming_bigdata\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\streaming_bigdata\kafka\libs\jopt-simple-5.0.4.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka_2.13-2.5.0-sources.jar;D:\streaming_bigdata\kafka\libs\kafka-clients-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-scala_2.13-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\streaming_bigdata\kafka\libs\kafka-tools-2.5.0.jar;D:\streaming_bigdata\kafka\libs\log4j-1.2.17.jar;D:\streaming_bigdata\kafka\libs\lz4-java-1.7.1.jar;D:\streaming_bigdata\kafka\libs\maven-artifact-3.6.3.jar;D:\streaming_bigdata\kafka\libs\metrics-core-2.2.0.jar;D:\streaming_bigdata\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-codec-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-handler-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\streaming_bigdata\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\streaming_bigdata\kafka\libs\paranamer-2.8.jar;D:\streaming_bigdata\kafka\libs\plexus-utils-3.2.1.jar;D:\streaming_bigdata\kafka\libs\reflections-0.9.12.jar;D:\streaming_bigdata\kafka\libs\rocksdbjni-5.18.3.jar;D:\streaming_bigdata\kafka\libs\scala-collection-compat_2.13-2.1.3.jar;D:\streaming_bigdata\kafka\libs\scala-java8-compat_2.13-0.9.0.jar;D:\streaming_bigdata\kafka\libs\scala-library-2.13.1.jar;D:\streaming_bigdata\kafka\libs\scala-logging_2.13-3.9.2.jar;D:\streaming_bigdata\kafka\libs\scala-reflect-2.13.1.jar;D:\streaming_bigdata\kafka\libs\slf4j-api-1.7.30.jar;D:\streaming_bigdata\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\streaming_bigdata\kafka\libs\snappy-java-1.1.7.3.jar;D:\streaming_bigdata\kafka\libs\validation-api-2.0.1.Final.jar;D:\streaming_bigdata\kafka\libs\zookeeper-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zookeeper-jute-3.5.7.jar;D:\streaming_bigdata\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,136] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\cmder\vendor\git-for-windows\cmd;D:\cmder\vendor\conemu-maximus5\ConEmu\Scripts;D:\cmder\vendor\conemu-maximus5;D:\cmder\vendor\conemu-maximus5\ConEmu;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Java\jdk1.8.0_281\bin;C:\Users\Gab\AppData\Local\Microsoft\WindowsApps;C:\Users\Gab\AppData\Local\Programs\Microsoft VS Code\bin;D:\cmder\vendor\git-for-windows\mingw64\bin;D:\cmder\vendor\git-for-windows\usr\bin;D:\cmder\vendor\bin;D:\cmder;. (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,138] INFO Client environment:java.io.tmpdir=C:\Users\Gab\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,139] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,139] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,140] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,140] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,140] INFO Client environment:user.name=Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,141] INFO Client environment:user.home=C:\Users\Gab (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,141] INFO Client environment:user.dir=D:\streaming_bigdata (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,142] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,142] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,143] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,146] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@50a638b5 (org.apache.zookeeper.ZooKeeper)
[2021-04-14 21:08:48,157] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2021-04-14 21:08:48,166] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2021-04-14 21:08:48,169] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 21:08:48,173] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 21:08:48,175] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:50781, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 21:08:48,183] INFO Creating new log file: log.19b (org.apache.zookeeper.server.persistence.FileTxnLog)
[2021-04-14 21:08:48,233] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100055c4a970000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2021-04-14 21:08:48,246] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 21:08:48,640] INFO Cluster ID = CTtipEoFQvqanzDqj07khg (kafka.server.KafkaServer)
[2021-04-14 21:08:48,725] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 21:08:48,781] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/temp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2021-04-14 21:08:48,855] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 21:08:48,855] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 21:08:48,857] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2021-04-14 21:08:48,894] INFO Loading logs. (kafka.log.LogManager)
[2021-04-14 21:08:49,015] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Loading producer state till offset 146 with message format version 2 (kafka.log.Log)
[2021-04-14 21:08:49,034] INFO [ProducerStateManager partition=twitter-0] Loading producer state from snapshot file 'D:\temp\kafka-logs\twitter-0\00000000000000000146.snapshot' (kafka.log.ProducerStateManager)
[2021-04-14 21:08:49,041] INFO [Log partition=twitter-0, dir=D:\temp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 146 in 117 ms (kafka.log.Log)
[2021-04-14 21:08:49,053] INFO Logs loading complete in 159 ms. (kafka.log.LogManager)
[2021-04-14 21:08:49,066] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2021-04-14 21:08:49,067] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2021-04-14 21:08:49,468] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2021-04-14 21:08:49,516] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2021-04-14 21:08:49,518] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2021-04-14 21:08:49,539] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:08:49,540] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:08:49,540] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:08:49,541] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:08:49,555] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2021-04-14 21:08:54,146] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-04-14 21:08:54,206] INFO Stat of the created znode at /brokers/ids/0 is: 425,425,1618445334161,1618445334161,1,0,0,72063487984467968,200,0,425
 (kafka.zk.KafkaZkClient)
[2021-04-14 21:08:54,208] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArraySeq(EndPoint(DESKTOP-N4251U6,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 425 (kafka.zk.KafkaZkClient)
[2021-04-14 21:08:54,299] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:08:54,304] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:08:54,305] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:08:54,337] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 21:08:54,338] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2021-04-14 21:08:54,345] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2021-04-14 21:08:54,365] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:10000,blockEndProducerId:10999) by writing to Zk with path version 11 (kafka.coordinator.transaction.ProducerIdManager)
[2021-04-14 21:08:54,390] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 21:08:54,393] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2021-04-14 21:08:54,393] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2021-04-14 21:08:54,419] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-04-14 21:08:54,440] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-04-14 21:08:54,491] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2021-04-14 21:08:54,499] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 21:08:54,500] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 21:08:54,501] INFO Kafka startTimeMs: 1618445334493 (org.apache.kafka.common.utils.AppInfoParser)
[2021-04-14 21:08:54,508] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-04-14 21:08:54,554] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(twitter-0) (kafka.server.ReplicaFetcherManager)
[2021-04-14 21:08:54,566] INFO [Partition twitter-0 broker=0] Log loaded for partition twitter-0 with initial high watermark 146 (kafka.cluster.Partition)
[2021-04-14 21:08:54,568] INFO [Partition twitter-0 broker=0] twitter-0 starts at leader epoch 0 from offset 146 with high watermark 146. Previous leader epoch was -1. (kafka.cluster.Partition)
[2021-04-14 21:18:54,347] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2021-04-14 21:28:54,349] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2021-04-14 21:31:53,383] WARN Session 0x100055c4a970000 for server localhost/0:0:0:0:0:0:0:1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: Se ha forzado la interrupción de una conexión existente por el host remoto
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(Unknown Source)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(Unknown Source)
	at sun.nio.ch.IOUtil.read(Unknown Source)
	at sun.nio.ch.SocketChannelImpl.read(Unknown Source)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:75)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1223)
[2021-04-14 21:31:55,419] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-04-14 21:31:55,946] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2021-04-14 21:31:55,948] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2021-04-14 21:31:57,444] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2021-04-14 21:31:57,554] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2021-04-14 21:31:59,101] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
